2.1. Reproducibility and Message Storage in the Chronicle Approach
The above approach to Microservices assumes that, at each stage, all messages that have passed through the stage are stored in perpetuity. This is key to being able to reproduce the data flow through the system, or some part of the system, at any time.
There are many advantages to this.
Diagnosing and fixing bugs in any part of the system becomes easier, since the failing component can be examined over and over using the same data that identified the problem in the first place. When a fix is applied, testing using the same data can verify that the bug is no longer present
Examining behaviour with the actual data being passed may identify algorithmic or data flow improvements, such as reducing the size of message payloads or removing redundant messages. This can be important in systems where latency must be minimised.
Prospective performance improvements may be easily tested, and refined, using production class data.
Clearly this approach places some considerable demands on the memory architecture of the (Java) applications. The normal Java heap is not suitable for storing all such messages, since the size required is likely to be well above the available physical memory on the machine where the application is running.
When a Java application heap size exceeds the amount of available physical memory there are seriously detrimental effects on the performance of the system. The host operating system has to page out portions of the heap to secondary storage, bringing them back into main memory when they are required again. The operating system has no knowledge of the layout of Java memory inside the heap and bases its decisions on which pages to evacuate to secondary storage solely on measures of when the page was last accessed.
The cost of garbage collection significantly increases as heap size grows to very large values, partly because of the sheer amount of work that must be performed during a collection, exacerbated by the costs of paging described above.
A solution is to use memory mapped files. These increase the amount of virtual memory that is available to a running Java application without affecting the size or operation of the garbage collected heap. The increase in available virtual memory does come at a cost, but this is relatively small in comparison to the benefit of having so much more memory available to the application.
Chronicle provides this functionality through Chronicle Queue. Chronicle Queue is open source software, whose efficiency and reliability has led to it being demonstrated as suitable for use in Microservices environments where latency in message passing is an important factor.
Chronicle Queue overlays data structures on the mapped files, allowing transparent access to the data in them from the application. Additionally, since files can be mapped into multiple processes, concurrent access to Queues from multiple JVMs (Microservices) is supported.
One of the reasons that mapped files provide high performance in this area is that changes to the data in the process are not directly written back to the file. The mapped files act as a write-back cache of the data on disk. This could result in a delay, typically around 50 microseconds per message, before the message is persisted to the disk file and presents a potential vulnerability in achieving the goal of guaranteeing that all messages are stored in perpetuity.
Chronicle avoids this by replicating a Queue to another JVM on a separate machine rather than relying on synchronising the messages to disk. In fact, the time taken to replicate can be significantly lower (less than 10 microseconds) than the time to store to even a SSD. Replication is a key feature of Chronicle Services and will be discussed in more detail later in this guide.
The sizes of the mapped files used by Chronicle Queues are such that Flow Control is not considered an issue. The files act as buffers between the components that are large enough to store enough data flow control is not needed, since there will always be enough space to store messages being written by a producer, even if the consumer is considerably slower in reading the messages. In the extreme case we can do without a consumer altogether, making these files into logs written by software components.