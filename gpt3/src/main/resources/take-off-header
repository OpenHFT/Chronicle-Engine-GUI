


Introduction

Overview
As is common with many other technologies, ranging from programming languages to frameworks, this site aims to
provide demonstrations of how Chronicle Services can be used in various scenarios.
The content is divided into sections, containing a number of recipes, each describing how to solve a particular problem.
1. Getting Started with Chronicle Services
Describes the structure of a Chronicle Service application and demonstrates how to build a simple example.
2. Working With Structured Data
Introduces the concept of Data Transfer Objects, which are used to allow structured data rather than primitive values
to be safely passed in messages to and from a Chronicle Service.
3.	Error Handling
Describes different approaches to handle errors in Chronicle Services applications.
4.	Packaging
Describes options for packaging applications based on Chronicle Services.
5. Configuration
Describes the features of Chronicle Services' declarative configuration model, and how to access and manipulate this
from program code.
6. Interfacing with External Components
Describes how to initiate messages and consume messages from outside a Chronicle Services application.
7. Additional Features of Services
Describes miscellaneous additional capabilities of Chronicle Services.
8. Managing State in Chronicle Services
Discusses issues with managing state in Chronicle Services application, and shows alternative mechanisms for
recreating a service's state after a restart.
9. Diagnostics and Monitoring
Describes techniques and tools for gathering diagnostic and monitoring data from a Chronicle Services Application.
1. Getting Started with Chronicle Services
Overview
This section describes how to get started with Chronicle Services, beginning with setting up build tools to enable access
to the libraries and tools of Chronicle Services. We also examine how to define, implement and test a simple Chronicle
Service that performs summation and finally show how to run the service in an application.
Recipes
1.1 Installing Chronicle Services
You want to use Chronicle Services in a project.
1.2 Defining a Chronicle Service
You want to define a Chronicle Service.
1.3 Testing a Chronicle Service
You want to test that the service generates the correct output messages when input messages are passed to it.
1.4 Running a Service in an Application
You want to run a service in a standalone Java application.


1.1 Installing Chronicle Services
Problem
You want to use Chronicle Services in a project.
Solution
Install Chronicle Services by adding the dependency to your project.
Discussion
Chronicle Services is a commercial product of Chronicle Software Ltd. You need to
obtain a license before you can use the software. More information can be found on Chronicle Software.
Once you have a license you can add the dependency to your build environment. If you are using Maven as your build
tool (as we recommend) then you can use this pom.xml file as a starting point.
Listing 1. pom.xml



Chronicle libraries are distributed using a BOM, hence the need for the <dependencyManagement> section. With this
set, Chronicle Services is accessed using the following dependency.

The additional dependencies shown in the file (e.g slf4j and junit) are used in our demo code but are not absolutely
necessary for Chronicle Services.


1.2 Defining a Chronicle Service
Problem
You want to define a Chronicle Service.
Solution
Define the service's public input and output interface, then provide an implementation class.
Discussion
A Chronicle Service accepts input messages/events from one or more sources, and outputs messages/events to one
sink. To define a service, you need to specify the message types expected as input and those generated as output as
Java interface types. Let's consider a simple example, where a service performs a simple addition of two numbers and
posts the result:

The service has one input and one output, these are defined as Java interfaces:
Listing 3. Service Input Interface

Listing 4. Service Output Interface

1.2 Defining a Chronicle Service
The service implementation is defined in the following class:
Listing 5. Service Implementation Class

The implementation class implements the SumServiceIn interface, indicating that it will accept messages/events
defined in this interface. A reference is maintained to an instance of the output interface, SumServiceOut,
providing a channel to output messages from the service. This reference is injected into the implementation class
during construction.
The project can be laid out following standard rule for a Maven project, shown here being managed using IntelliJ Idea:

1.2 Defining a Chronicle Service
1.3 Testing a Chronicle Service
Problem
You want to test that the service generates the correct output messages when input messages are passed to it.
Solution
Use the Chronicle Services YAMLTester framework.
Discussion
YAMLTester supports interface-based testing of Chronicle Services, by creating a harness that passes messages to an
instance of the service, and intercepting the corresponding output to verify that it is correct in each case.
YAMLTester builds on JUnit, and the following additions to the project structure supply the necessary configuration
to run the tests:

Specifying the test case
As this is a simple service we can base our test on a simple use case, namely verifying that for inputs [3,4] the service
will respond with 7.
We write the input message, and expected output for that message, in YAML files in the directory
src/test/resources/test/sum
Listing 6. in.yaml - Input messages in YAML

9 of 134 |



Listing 7. out.yaml - Expected output in YAML

Running the test
The test is run using JUnit, so we need to define a JUnit test case:
Listing 8. JUnit test case to run the YAML test

When the test is run, the test harness in YamlTester.testMessages will
1.	Create an instance of the service
2.	Inject an instance of the output interface
3.	Pass the messages in the in.yaml file that is found in the specified directory
4.	Capture the output messages and compare them with the expected output from the out.yaml file.
Tests may be run from the command line using Maven or from the IDE.
Using Maven:
$ mvn test
...
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running SumTest
[main] INFO net.openhft.chronicle.core.Jvm - Chronicle core loaded from
file:/Users/george/.m2/repository/net/openhft/chronicle-core/2.23.35/chronicle-
core-2.23.35.jar
[main] WARN net.openhft.chronicle.wire.GenerateMethodWriter - Generated code to
call
updateInterceptor for public abstract void
software.chronicle.example1.api.Responder.result(double) will box and generate
garbage
[main] INFO software.chronicle.example1.services.SumServiceImpl - Processing
sum(3.0,4.0)
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed:
0.835 sec Results :
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  2.121 s
[INFO] Finished at: 2022-12-06T08:58:57Z
[INFO] ------------------------------------------------------------------------
  Process finished with exit code
0 From IntelliJ:

If the expected output in the file out.yaml is changed, then the test will fail:
$ mvn test
...
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running SumTest
[main] INFO net.openhft.chronicle.core.Jvm - Chronicle core loaded from
file:/Users/george/.m2/repository/net/openhft/chronicle-core/2.23.35/chronicle-
core-2.23.35.jar
[main] WARN net.openhft.chronicle.wire.GenerateMethodWriter - Generated code to
call
updateInterceptor for public abstract void
software.chronicle.example1.api.Responder.result(double) will box and
generate garbage [main] INFO
software.chronicle.example1.services.SumServiceImpl - Processing sum(3.0,4.0)
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.817 sec <<<
FAILURE! testSum(SumTest)  Time elapsed: 0.776 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<...ogether
---
sumResult: [8].0
...> but was:<...ogether
---
sumResult: [7].0
...>
    at org.junit.Assert.assertEquals(Assert.java:117)
    at org.junit.Assert.assertEquals(Assert.java:146)

Or from IntelliJ:

By following the link <Click to see differences> we can examine the differences to diagnose the problem:

Clearly the expected output is wrong, so we can fix it and the test will pass.


1.4 Running a Service in an Application
Problem
You want to run a service in a standalone Java application.
Solution
Define supporting components, and define the application declaratively in a configuration file.
Discussion
Chronicle Services provides a comprehensive runtime that takes care of the configuration and management of one or
more services inside a standalone Java application. From a single driver class, it is possible to start and configure
multiple service implementations, connecting them together using one or more Chronicle Queue instances as the
transport for messages and events. A service that has been implemented and unit-tested as described in earlier recipes
can be incorporated into such an application with no code changes.
Chronicle Service based applications are designed to support an Event-based architecture, where events move through
a stream of services. This recipe describes an application that follows this architecture.
In order to run the application completely within the Chronicle Services runtime, it is necessary to provide two
additional components. The main service receives messages/events from an upstream service, and resulting
messages/events are passed to a downstream service. These additional components serve purely as a source and a
sink for messages, and introduce no additional processing.
The architecture of the application can be seen in the following diagram:

The sumServiceSink Queue represents an output for the sumDownstream service. Although this service does
not generate any output messages, it is a requirement that every service has one and only one output queue.
The main service implementation remains unchanged from Recipe 1.2.
The Upstream Service
The sumUpstream service exists as a source of messages that are sent via the sumServiceIn queue to the
sumService. Its implementation is very straightforward:
Listing 9. Upstream service providing input to the main service

By implementing the ServiceLifecycleListener interface, the service will receive a callback from the
Chronicle Services runtime, via the start() method, once initialisation is complete. At this time it constructs and
sends a single message to its output queue.
The Downstream Service
The sumDownstream service receives output messages that are posted by the sumService to the
sumServiceOut queue. It will simply log details of these messages, not posting any further output.
Once again, its implementation is straightforward:
Listing 10. Downstream service consuming output messages from the main service

Defining the Application
All of the components described above are wired together to form the application using a configuration file, by default
named services.yaml.
Listing 11. services.yaml

Firstly, the Chronicle Queues required by the application are specified. There are two queues that act as input and
output for the service, and a third that serves as an output for the downstream service. The path option specifies
where the file that is used as backing store for the queue is to be stored. In the example. For demo purposes, these
files are located in the target directory of the project so that they can easily be removed when required through a
Maven "clean" operation.
For each service, the file specifies its connection to the appropriate queue(s), as well as the fully qualified name of the
service's implementation class.
Further configuration is possible through this file, this will be seen in later recipes.
Running the Application
To run the application it is necessary to provide a class that acts as an application entrypoint. This class


lives outside the Chronicle Services runtime; it serves principally to start the runtime using the services.yaml file
to drive the application.
Listing 12. Application entry point

When this class is used as the application entrypoint, three actions take place
1.	All files in the queues' data directory are deleted. This is to ensure that no pre-existing queues are left from any
previous runs of the application since they may contain stale data that would interfere with the current run, and is
done primarily for demo purposes.
2.	The Chronicle Services method ThreadRunner.runAll() reads the specified configuration file, and starts all
of the services that are defined therein. Chronicle Queues are started to carry messages between the services if
required (due to the previous action this should always result in new queues being created). Each service is started
in its own thread.
3.	The main application thread pauses for 3 seconds and then terminates. Since by default all service threads created
in the previous step are daemon threads, this will cause all the services to shut down.
The running demo service displays a significant number of log messages, including the following:
...
 _____ _                     _      _        _____                 _
/  __ \ |                   (_)    | |      /  ___|               (_)
| /  \/ |__  _ __ ___  _ __  _  ___| | ___  \ `--.  ___ _ ____   ___  ___ ___
___
| |   | '_ \| '__/ _ \| '_ \| |/ __| |/ _ \  `--. \/ _ \ '__\ \ / / |/ __/ _ \/
__|
| \__/\ | | | | | (_) | | | | | (__| |  __/ /\__/ /  __/ |   \ V /| | (_|  __/\__
\
 \____/_| |_|_|  \___/|_| |_|_|\___|_|\___| \____/ \___|_|    \_/
|_|\___\___||___/
:: Chronicle Services ::              (3.23.38) Running under Java(TM) SE
Runtime Environment 1.8.0_162-b12 with 16 processors reported.
Process id:
73566 ...
[main/sumService] INFO Runner - Starting service sumService
[main/sumUpstream] INFO Runner - Starting service
sumUpstream [main/sumDownstream] INFO Runner - Starting
service sumDownstream ...
[main/sumUpstream] INFO RunLoopControllerMain - running
sumUpstream... ... [main/sumDownstream] INFO
RunLoopControllerMain - running sumDownstream... ...
[main/sumService] INFO RunLoopControllerMain - running sumService...
[main/sumService] INFO SumServiceImpl - Processing sum(3.0,7.0)
[main/sumDownstream] INFO SumServiceDownstream - Result:
10.0 Process finished with exit code 0
You can see this demo running by clicking the following button:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example1 && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
There are other ways to start and manage a Chronicle Services application - these will be shown in later recipes.
Project Structure
With all the features described in the recipes in this section, the project structure will be:

2. Working With Structured Data
Overview
Normally, Chronicle Services will be defined to accept structured data rather than primitive values as input, and to
generate structured data as responses. This section will show how to define services that operate in this way, and how
to test them using the same mechanisms as in the simple example.
Services using structured data are run inside applications in exactly the same way as for the simple example in the
previous section..
Recipes
2.1 Using Structured Data as Message Payloads 2.2 Testing With DTOs 2.3 Using DTOs in an
Application

18 of 134 | Overview


2.1 Using Structured Data as Message Payload
Problem
You want to send and receive messages containing data structures.
Solution
Use DTOs encoded and decoded by Chronicle Wire.
Discussion
In order to effectively implement business logic, most services will require messages to contain more than just Java
primitive values. Ensuring data integrity, while at the same time maintaining performance and latency targets, is a
significant problem. In Chronicle Services, the Chronicle Wire library is used to provide an effective solution, with
minimal overhead in terms of memory or time.
To examine this, we will use a different example from that in the previous section. The example service performs some
simple balance tracking on an account, based on credit and debit transactions. A second service acts as a mock client
for this service.
The architecture of this example is shown below:

Introducing Data Transfer Objects
A Data Transfer Object (DTO) is a POJO that carries data relevant to a message/event that is persisted or sent as the
body of the message/event. Chronicle libraries use DTOs both as message payloads and as a means of efficiently
managing the storage of Java objects, especially those used in configuration, in persistent storage. We have already
seen an example of this, namely the application configuration file services.yaml.
Using DTOs in a Chronicle Service
The public interface of the Transaction Service for input is shown here:
Listing 13. Input interface for Transaction Service

The accounts message represents a request to add the list of accounts passed as the parameter to the list of
managed accounts. The transaction message is a request to apply the specified Credit or Debit transaction to the
relevant account.
Output from the Transaction Service is specified here:
Listing 14. Output interface for Transaction Service

The message contains the details of a single account, after a given transaction has been applied.
Defining the DTOs
From the above, we can see there are two DTOs that we need to define. First, to hold details of an Account:
Listing 15. Account DTO


Next to hold details of a transaction
Listing 16. Transaction DTO

We also define a third type to describe the type of transaction that is being applied:
Listing 17. Transaction type DTO

In both DTOs, the classes extend the type SelfDescribingMarshallable. This acts as the hook into the
functionality of Chronicle Wire (through additional types not shown here), and also defines which of the efficient
binary formats to use (the SelfDescribing format, which encodes property names along with property values).
Functionality is also provided to support efficient comparison of DTOs (i.e. equals() and hashcode()
implementations) as well as a convenient way of generating a String representation for logging/diagnostics (i.e.
toString()).
Defining the Service
The service implementation for TransactionService is shown below.
Listing 18. Transaction service implementation public class
TransactionSvcImpl implements TransactionSvcIn {
  private static Logger LOG = LoggerFactory.getLogger(TransactionSvcImpl.class);
  static {
    CLASS_ALIASES.addAlias(Account.class);
  }
  private final TransactionSvcOut out;
  private final Map<Long, Account> balanceByAccount = new HashMap<>();
  private final List<Account> balances = new ArrayList<>();
  public TransactionSvcImpl(TransactionSvcOut out) {
    this.out = out;
  }
  @Override
  public void transaction(Transaction transaction) {
    LOG.info("Applying {} of {} to account {}", transaction.entry(),
transaction.amount(),
transaction.accountNumber());     Account account =
balanceByAccount.get(transaction.accountNumber());
    account.add(transaction.entry() == Entry.CREDIT  transaction.amount() : -
transaction. amount());
    LOG.info("Balance of account {} is now {}", account.accountNumber(),
account.balance());
    out.onTransaction(account);
  }
  @Override
  public void accounts(List<Account> accounts) {
    for (Account account : accounts) {
      LOG.info("Adding account {} with initial balance: {}",
account.accountNumber(), account
.balance());
      this.balanceByAccount.put(account.accountNumber(), account);

1.	The class implements the public service interface.
2.	This is an optimisation in Chronicle Wire that encodes the class name as its short form rather than its fully qualified
form. More details can be found in the Chronicle Wire documentation
3.	Account details are stored in a Map, keyed by account number. Note this is purely for demo purposes and should
not be considered a recommendation for managing this state in general.
4.	In the constructor, a reference to the transport for output messages is injected.
5.	The handler for transaction messages. Updates the balance of the account and output a message containing the
new balance of the account.
6.	This request adds the accounts in the list to the current set of accounts being monitored, and is important for
testing, as will be seen shortly.
DTO Encoding
The Chronicle Services runtime uses Chronicle Wire to encode the DTOs into messages that are sent to and from the
service. Firstly, the transaction requests: Listing 19. Sample Transaction message in YAML

and the response messages:
Listing 20. Sample response message in YAML

Project Structure
The layout of a project using DTOs is recommended to follow the structure below:



The api directory contains the definitions of the various public interfaces. The dto directory contains the DTO class
definitions, and the services directory contains the definitions of the service implementation classes. No changes
are required to the pom.xml file from the one described in Recipe 1.1, since the Chronicle Wire library will
automatically be made available through the chronicle-services dependency and BOM.
2.2 Testing with DTOs
Problem
You want to perform functional tests on a stateful service that uses DTOs.
Solution
Use YAMLTester, which supports DTOs and simple state initialisation.
Discussion
As in Recipe 1.3, you can use YAMLTester to test the service's functionality. However, in this case a little more work
is required. The account manager service is stateful, in that it maintains a note of the current balance of each valid
account. To test functionality we need to provide some initial data in the form of accounts with an initial balance.
Specifying Initial State for Tests
Fortunately YAMLTester allows this to be done easily, by sending the service an "initialisation" message before the
core requests. Initialisation messages are specified in the file setup.yaml, which should be located in the same
directory as the other files used for YAMLTester:

The contents of the file are a message for the TransactionService to add accounts to its current list:
Listing 21. Setup for YAML test


Defining Test Cases
Now let's see the in.yaml file, containing the input messages to test: Listing 22.
Input messages for testing the Transaction Service

and the expected output from these, from the out.yaml file:
Listing 23. Expected output from the Transaction Service

Running the Tests
When the test is run, the log messages will display information to illustrate progress:
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl -
Adding account 34343434 with initial balance: 100.0
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl - Adding
account
45454545 with initial balance: 200.0
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl -
Applying DEBIT of
100.0 to account 34343434
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl -
Balance of account
34343434 is now 0.0
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl -
Applying DEBIT of 50.0
to account 34343434
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl -
Balance of account
34343434 is now -50.0
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl -
Applying CREDIT of
10.0 to account 45454545
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl -
Balance of account
45454545 is now 210.0
If any of the test cases fail, when actual and expected results are different, then an indication of where the difference
occurred will be shown. For example, if the second example output was entered as:

then we would see:
$ mvn test
...
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running software.chronicle.services.demo.BalanceTest
[main] INFO net.openhft.chronicle.core.Jvm - Chronicle core loaded from
file:/Users/george/.m2/repository/net/openhft/chronicle-core/2.23ea34/chronicle-
core-2.23ea34.jar
[main] INFO software.chronicle.services.demo.services.TransactionSvcImpl - Adding
account
34343434 with initial balance: 100.0
...
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.881 sec <<<
FAILURE!
testBalance(software.chronicle.services.demo.BalanceTest)  Time elapsed: 0.839
sec  <<< FAILURE! org.junit.ComparisonFailure: expected:<...4343434,
  balance: []50.0
} .
..
---
accou...> but was:<...4343434,
  balance: [-]50.0
} .
..


--
accou...>
    at org.junit.Assert.assertEquals(Assert.java:117)
    at org.junit.Assert.assertEquals(Assert.java:146)
...
Results :
Failed tests:
testBalance(software.chronicle.services.demo.BalanceTest):
expected:<...4343434,(..) Tests run: 1, Failures: 1, Errors:
0, Skipped: 0
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  3.043 s
[INFO] Finished at: 2022-11-04T14:03:33Z
[INFO] ------------------------------------------------------------------------
Running the test from Intellij Idea, we would see the same results presented through the test output window:

By clicking to see the differences that caused the failure, we will be shown the expected and actual output side by side:

From this output it's clear what needs to be changed, to make the test pass.
2.3 Using DTOs in an Application
Problem
You want to run a DTO based service in an application.
Solution
Use declarative configuration from the services.yaml file.
Discussion
There is no difference in running a DTO based service, such as the Transaction Service described in this section as an
application, from the previous section where the Sum Service was run as an application.
In order to run the application completely within the Chronicle Services runtime, it is necessary to provide two
additional components. The main service receives messages/events from an upstream service, and resulting
messages/events are passed to a downstrean service. These additional components serve purely as a source and a sink
for messages, and introduce no additional processing.
The architecture of the application can be seen in the following diagram:

The transactionSink Queue represents output for the transactionDownstream service, even although the
service does not produce any output. It is a requirement of the API, however, that every service has one and only one
output queue.
The main service remains unchanged from that shown in Recipe 2.1.
The Upstream Service
The transactionUpstream service exists as a source of messages that are sent via the transactionIn queue
to the transactionService. Its implementation is straightforward:
Listing 24. Upstream service for Transaction Service application
public class TransactionSvcUpstream implements ServiceLifecycleListener {
  private static final Logger LOG =
LoggerFactory.getLogger(TransactionSvcUpstream.class);
  private TransactionSvcIn out;
  private final Transaction transaction = new Transaction();
  public TransactionSvcUpstream(TransactionSvcIn out) {
    this.out = out;


  }
  @Override
  public void start() {
    List<Account> initAccounts = Arrays.asList(
        new Account("currentAccount", 34343434, 100.0),
        new Account("savingsAccount", 45454545, 200.0)
    );
    out.accounts(initAccounts);

out.transaction(transaction.accountNumber(34343434).entry(Entry.DEBIT).amount(100));

out.transaction(transaction.accountNumber(34343434).entry(Entry.DEBIT).amount(50));

out.transaction(transaction.accountNumber(45454545).entry(Entry.CREDIT).amount(10));
  }
}
By implementing the ServiceLifecycleListener interface, the service will receive a callback from the
Chronicle Services runtime, via the start() method, once initialisation is complete. Inside this method, a short list of
Account objects is created, and passed to the service via the accounts() method, in order to create the accounts
on which the transactions will be applied. Three transaction() events are then posted to the service's input
queue, from where they will be read and processed.
The Downstream Service
The transactionDownstream service receives output messages that are posted by the transactionService
to the transactionServiceOut queue. It will simply log details of these messages, and not post any further
output.
Once again, its implementation is straightforward:
Listing 25. Downstream service to consume messages output by Transaction Service

Application Configuration
Details of the orchestration of the services is in the services.yaml file:
Listing 26. Configuration file

Running the Application
The following class acts as an entrypoint for the application:
Listing 27. Driver program for Transaction Service

1.	As this is a demo, the application ensures that all previous queues deleted, to avoid any stale data from previous
runs.
2.	All resources defined in the services.yaml file are created and initialised. Each service will, by default, run in
its own thread.
3.	The upstream service will have sent messages to the service. The driver waits for 3 seconds to ensure they are all
processed and the results can be examined, and then closes down. Since the service threads are daemon threads,
they will all shut down at this point.
Log messages will indicate the progress of the application.
Run this yourself by clicking the button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example2 && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
 ...
  _____ _                     _      _        _____                 _
/  __ \ |                   (_)    | |      /  ___|               (_)
| /  \/ |__  _ __ ___  _ __  _  ___| | ___  \ `--.  ___ _ ____   ___  ___ ___
___
| |   | '_ \| '__/ _ \| '_ \| |/ __| |/ _ \  `--. \/ _ \ '__\ \ / / |/ __/ _ \/
__|
| \__/\ | | | | | (_) | | | | | (__| |  __/ /\__/ /  __/ |   \ V /| | (_|  __/\__
\
 \____/_| |_|_|  \___/|_| |_|_|\___|_|\___| \____/ \___|_|    \_/
|_|\___\___||___/
:: Chronicle Services ::             (3.23ea37) Running under Java(TM) SE
Runtime Environment 1.8.0_162-b12 with 16 processors reported.
Process id:
36171 ...
[main/transactionUpstream] INFO Runner - runInitializationComplete
[main/transactionUpstream] INFO RunLoopControllerMain - running
transactionUpstream... ...
[main/transactionDownstream] INFO Runner - runInitializationComplete
[main/transactionDownstream] INFO RunLoopControllerMain - running
transactionDownstream... ...
[main/transactionSvc] INFO Runner - runInitializationComplete
[main/transactionSvc] INFO RunLoopControllerMain - running transactionSvc...
[main/transactionSvc] INFO TransactionSvcImpl - Adding account 34343434 with
initial balance:
100.0 [main/transactionSvc] INFO TransactionSvcImpl - Adding account 45454545
with initial balance:
200.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Balance of account 34343434 is
now 0.0
[main/transactionSvc] INFO DiskSpaceMonitor - Took 0.322 ms to pollDiskSpace for
/Users/george/work/Chronicle/Chronicle-Services-Demo/target/data/transactionOut
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Balance of account 34343434 is
now -50.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545
[main/transactionSvc] INFO TransactionSvcImpl - Balance of account 45454545 is
now 210.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Account 34343434 has
balance 0.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Account 34343434 has
balance -50.0 [main/transactionDownstream] INFO TransactionSvcDownstream -
Account 45454545 has balance 210.0 Process finished with exit code 0


3. Error Handling
Overview
Not all messages can be processed successfully, and therefore part of the contract for a service should specify how
errors are handled. Chronicle Services considers two broad types of errors that are divided into expected errors and
unexpected errors.
Broadly speaking, an expected error is one whose possibility is known about beforehand, and from which it may be
possible to recover without restarting a service and invoking failover or other High Availability (HA) behaviour. An
unexpected error is essentially tied to the occurrence of a Java exception in the service, and will normally result in the
service being unable to continue handling requests.
In Chronicle Services there are no hard rules about how to deal with errors. However, there are some patterns that will
help in making applications more robust in their presence. These patterns are described in this section.
Recipes
3.1 Using DTOs to Indicate Success
You want to indicate whether a message was successfully processed or not using the same response DTO.
3.2 Testing a Service with Success or Failure in Output DTOs
You want to test a service that uses the pattern of returning success/failure indication in output DTOs.
3.3 Separating Success and Error Handling
You want to process errors from a service in a completely separate path to successful results.
3.4 Testing Separate Error Handling
You want to test a service that uses a separate error message with its own DTO.
34 of 134 | Overview
3.1 Using DTOs to Indicate Success
Problem
You want to indicate whether a message was successfully processed or not using the same response DTO.
Solution
Define DTOs to encapsulate success or failure.
Discussion
This recipe is based on the Transaction Service example discussed in earlier recipes.
Consider the application of a debit transaction to an account. The result of this transaction may take the balance to
below 0, i.e. overdraft. The rules surrounding whether this should be allowed are part of the business logic of the
overall service. At the simplest level, for some accounts an overdraft may be allowed, whereas for others any
transaction that would result in an overdraft should be declined.
The success or failure of a transaction for reasons such as this can be brought into the service through some relatively
straightforward refactoring. In terms of the public interface of the service, the input API is the same:
Listing 28. Input interface for Transaction Service

To introduce the notion of success/failure, we can alter the DTO to carry this information. We also need to alter the
outgoing API to reflect this: Listing 29. Output interface for Transaction Service

The DTO can be seen below:
Listing 30. DTO for Transaction Service output


The DTO for output extends the corresponding DTO for which it is the result. It adds a boolean flag to indicate whether
processing completed successfully and an accompanying String giving more information. (Clearly it is possible to use
a more structured way of representing the "reason", for now String is used to make the demo easier to follow.)
Setting the Response DTO
The service implementation for the Transaction Service checks the incoming transaction request and builds the
response message based on the new DTO:
Listing 31. Implementation of Transaction Service public class TransactionSvcImpl
implements TransactionSvcIn {   private static Logger LOG =
LoggerFactory.getLogger(TransactionSvcImpl.class);
  static {
    CLASS_ALIASES.addAlias(Account.class);
  }
  private final TransactionSvcOut out;
  private final Map<Long, Account> balanceByAccount = new HashMap<>();
  private final List<Account> balances = new ArrayList<>();
  private OnTransaction onTransaction = new OnTransaction();
  public TransactionSvcImpl(TransactionSvcOut out) {
    this.out = out;
  }
  @Override
  public void transaction(Transaction transaction) {
    LOG.info("Applying {} of {} to account {}", transaction.entry(),
transaction.amount(),
transaction.accountNumber());


    Account account = balanceByAccount.get(transaction.accountNumber());
    onTransaction.reset();
    transaction.copyTo(onTransaction);
    if ((transaction.entry() == Entry.DEBIT) && (account.balance() <
transaction.amount())) {

      LOG.info("Bad transaction: Account {} has insufficient funds for debit: {}
[{}]",
          account.accountNumber(), transaction.amount(), account.balance());
      out.onTransaction(
          onTransaction
              .success(false)
              .reason("Insufficient funds " + account.balance() + " available for "
+
transaction.amount()));
      return;
    }
    account.add((transaction.entry() == Entry.CREDIT  transaction.amount() : -
transaction. amount()));
    LOG.info("Succeeded: Balance of account {} is now {}", account.accountNumber(),
account
.balance());
    out.onTransaction(
        onTransaction
            .success(true)
            .reason("Balance of account " + account.accountNumber() + "
now " + account. balance()));   }
  @Override
  public void accounts(List<Account> accounts) {
    for (Account account : accounts) {
      LOG.info("Adding account {} with initial balance: {}",
account.accountNumber(), account
.balance());
      this.balanceByAccount.put(account.accountNumber(), account);
    }
  }
}
1.	A single instance of the output DTO is created per service instance. There is no need to synchronize access since
Chronicle Services processes incoming messages on a single thread.
2.	Reuse the output DTO to reduce object creation and hence garbage collection. The current contents are cleared
and then the non-transient state of the incoming transaction is copied into the object. These methods are part of
the Chronicle Wire library.
3.	Check to see if the transaction should be allowed - in this case if the transaction would take the account balance
negative, then the remaining fields of the output DTO are filled in to indicate failure with an explanatory String
message. The output message is posted and the method returns.
4.	By this stage, the transaction is allowed, so calculate and set the new balance, complete the output DTO with a
success indication, post the message and return.
Processing the Output Message
Because the same message type is used for successful and failed transactions, the service reading the output (in this
case the transactionDownstream service) must discriminate between the two cases.
For example:
Listing 32. Handler for Transaction Service output messages

For a given message type, there can only be one handler. So the handler must decide on what processing is necessary
based on the success of the transaction that generated the message.
Running the Application
We can now run our modified application to observe how the transaction service cancels transactions that would
result in a negative account balance.
Log messages will indicate the progress of the application.
Run this yourself by clicking the button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example3a && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
 _____ _                     _      _        _____                 _
/  __ \ |                   (_)    | |      /  ___|               (_)
| /  \/ |__  _ __ ___  _ __  _  ___| | ___  \ `--.  ___ _ ____   ___  ___ ___
___
| |   | '_ \| '__/ _ \| '_ \| |/ __| |/ _ \  `--. \/ _ \ '__\ \ / / |/ __/ _ \/
__|
| \__/\ | | | | | (_) | | | | | (__| |  __/ /\__/ /  __/ |   \ V /| | (_|  __/\__
\
 \____/_| |_|_|  \___/|_| |_|_|\___|_|\___| \____/ \___|_|    \_/
|_|\___\___||___/
:: Chronicle Services ::      (unknown version) Running under OpenJDK Runtime
Environment 11.0.17+8-jvmci-22.3-b08 with 8 processors reported.
Process id:
45828 ...
[main/transactionSvc] INFO Runner - Starting service transactionSvc
[main/transactionUpstream] INFO Runner - Starting service
transactionUpstream [main/transactionDownstream] INFO Runner -
Starting service transactionDownstream ...
[main/transactionUpstream] INFO Runner - runInitializationComplete
[main/transactionUpstream] INFO RunLoopControllerMain - running
transactionUpstream...
...
[main/transactionDownstream] INFO Runner - runInitializationComplete
[main/transactionDownstream] INFO RunLoopControllerMain - running
transactionDownstream...
...
[main/transactionSvc] INFO Runner - runInitializationComplete
[main/transactionSvc] INFO RunLoopControllerMain - running transactionSvc...
[main/transactionSvc] INFO TransactionSvcImpl - Adding account 34343434 with
initial balance:
100.0 [main/transactionSvc] INFO TransactionSvcImpl - Adding account 45454545
with initial balance:
200.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now 0.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Bad transaction: Account 34343434
has
insufficient funds for debit: 50.0 [0.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
210.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Success: Balance of
account 34343434
now 0.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Failed: Insufficient
funds 0.0
available for 50.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Success: Balance of
account 45454545
now 210.0


3.2 Testing a Service with Success or Failure in Output DTOs
Problem
You want to test a service that uses the pattern of returning success/failure indication in output DTOs.
Solution
Use the YAMLTester to construct scenarios that are expected to succeed and fail.
Discussion
It is straightforward to use YAMLTester to test for success or failure in output DTOs. Recipe 3.1 describes how to
incorporate this into a service; test cases can be constructed to exercise this approach in the same way as shown
before.
The test setup is in the setup.yaml file:
Listing 33. Set for the YAML test

Input messages are the same as in the previous chapter:
Listing 34. Input Messages for the test

40	of 134 | 3.2 Testing a Service with Success or Failure in Output DTOs

The second case should cause a failure, since the modified service does not allow the balance of an account to become
negative
Listing 35. Expected output based on input messages


41	of 134 | 3.2 Testing a Service with Success or Failure in Output DTOs
3.3 Separating Success and Error Handling
Problem
You want to process errors from a service in a completely separate path to successful results.
Solution
Define separate DTOs for errors and add explicit handling to the API.
Discussion
For some classes of errors, it is desirable to completely separate error messages from non error messages that are
generated by a service. This could be done either at the downstream service for convenience, or for design reasons,
based on the nature of the error being represented. Consider the situation where a message is sent to the
Transaction Service containing an account number that does not exist. This is a somewhat more fundamental
problem than an error in the requested transaction (as described in Recipe 3.1), as it implies that all subsequent
transactions on that account will fail.
Updating the API to include Error Messages
Since the service may now post a separate message for errors, the output API must be altered to reflect this:
Listing 36. Input interface for Transaction Service

The DTO for the error message needs to be defined, this is done like all other DTOs:
Listing 37. DTO for Error Message




Although it is intended for separate processing, the DTO is defined in the same way as for the success case. By
extending the SelfDescribingMarshallable class the DTO will be serialized by Chronicle Wire in the expected
way. In this case the DTO has three pieces of information:
1.	The account number for which the error occurred.
2.	A String describing the error - as before, this can be more sophisticated if required, including further data that
could help diagnose the root cause of the error.
3.	A priority, which is defined using a Chronicle Services enum type allowing LOW, MEDIUM, HIGH or UNKNOWN to be
specified.
As it is now part of the API for the service, any component that will receive messages from the service must provide a
handler for the message. So the downstream service for the Transaction service needs to be extended with a
handler for AccountErrors:
Listing 38. Downstream handler for AccountError message
  @Override
  public void accountError(AccountError accountError) {
    LOG.error("Error for account {}: {} [{}]",
        accountError.accountNumber(), accountError.errorMessage(),
accountError.priority());
  }
Here, the method simply logs the occurrence of the error, but of course more sophisticated processing is allowed.
Lastly, the Transaction service will need to contain code that generates and returns the error message if the
conditions for it are found, so the transaction handler method is modified:
Listing 39. Transaction Service implementation with check for valid account number

  private static Logger LOG = LoggerFactory.getLogger(TransactionSvcImpl.class);
  static {
    CLASS_ALIASES.addAlias(Account.class);
  }
  private final TransactionSvcOut out;
  private final Map<Long, Account> balanceByAccount = new HashMap<>();
  private final List<Account> allAccounts = new ArrayList<>();
  private OnTransaction onTransaction = new OnTransaction();
  private AccountError accountError = new AccountError();
  public TransactionSvcImpl(TransactionSvcOut out) {
    this.out = out;
  }
  @Override
  public void transaction(Transaction transaction) {
    LOG.info("Applying {} of {} to account {}",
        transaction.entry(), transaction.amount(), transaction.accountNumber());
    Account account =
balanceByAccount.get(transaction.accountNumber());         if
(account == null) {
      LOG.error("Unknown account number: {}", transaction.accountNumber());
      accountError.reset();
      accountError.accountNumber(transaction.accountNumber())
          .errorMessage("Unknown Account Number")
          .priority(Priority.MEDIUM);
      out.accountError(accountError);
      return;
    }
    onTransaction.reset();
    transaction.copyTo(onTransaction);
    if ((transaction.entry() == Entry.DEBIT) && (account.balance() <
transaction.amount())) {
      LOG.info("Bad transaction: Account {} has insufficient funds for debit: {}
[{}]", account
.accountNumber(), transaction.amount(), account.balance());
      out.onTransaction(onTransaction.success(false).reason("Insufficient funds "
+ account
.balance() + " available for " + transaction.amount()));
      return;
    }
    account.add((transaction.entry() == Entry.CREDIT  transaction.amount() : -
transaction. amount()));
    LOG.info("Succeeded: Balance of account {} is now {}", account.accountNumber(),
account
.balance());
    out.onTransaction(onTransaction.success(true).reason("Balance of account " +
account
.accountNumber() + " now " + account.balance()));
  }
  @Override
  public void accounts(List<Account> accounts) {
    for (Account account : accounts) {

1.	A single instance of the AccountError DTO is maintained for each service instance. The single threaded nature
of message handling in a Chronicle Service means that there will be no contention for this object.
2.	If the lookup of the account in the map of known accounts fails, then clear out the existing error DTO, fill in the
details of the error and post the error message to the output.
Running the Application
With the latest modifications to the application we can observe how the transaction service posts an error to the
downstream service when it receives transactions for an unknown account.
Log messages will indicate the progress of the application:
Run this demo yourself by clicking on the run button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example3b && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
Listing 40. Log messages from the service
 _____ _                     _      _        _____                 _
/  __ \ |                   (_)    | |      /  ___|               (_)
| /  \/ |__  _ __ ___  _ __  _  ___| | ___  \ `--.  ___ _ ____   ___  ___ ___
___
| |   | '_ \| '__/ _ \| '_ \| |/ __| |/ _ \  `--. \/ _ \ '__\ \ / / |/ __/ _ \/
__|
| \__/\ | | | | | (_) | | | | | (__| |  __/ /\__/ /  __/ |   \ V /| | (_|  __/\__
\
 \____/_| |_|_|  \___/|_| |_|_|\___|_|\___| \____/ \___|_|    \_/
|_|\___\___||___/
:: Chronicle Services ::      (unknown version) Running under OpenJDK Runtime
Environment 11.0.17+8-jvmci-22.3-b08 with 8 processors reported.
Process id:
49368 ...
[main/transactionSvc] INFO Runner - Starting service transactionSvc
[main/transactionDownstream] INFO Runner - Starting service transactionDownstream
[main/transactionUpstream] INFO Runner - Starting service
transactionUpstream ...
[main/transactionUpstream] INFO Runner - runInitializationComplete
[main/transactionUpstream] INFO RunLoopControllerMain - running
transactionUpstream...
[main/transactionSvc] INFO Runner - runInitializationComplete
[main/transactionSvc] INFO RunLoopControllerMain - running transactionSvc...
[main/transactionSvc] INFO TransactionSvcImpl - Adding account 34343434 with
initial balance:
100.0 [main/transactionSvc] INFO TransactionSvcImpl - Adding account 45454545
with initial balance:
200.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now 0.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434


[main/transactionSvc] INFO TransactionSvcImpl - Bad transaction: Account 34343434
has
insufficient funds for debit: 50.0 [0.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
210.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 1000.0 to
account 99999999
[main/transactionSvc] ERROR TransactionSvcImpl - Unknown account number: 99999999
[main/transactionDownstream] INFO Runner - runInitializationComplete
[main/transactionDownstream] INFO RunLoopControllerMain - running
transactionDownstream...
[main/transactionDownstream] INFO TransactionSvcDownstream - Success: Balance of
account 34343434
now 0.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Failed: Insufficient
funds 0.0
available for 50.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Success: Balance of
account 45454545
now 210.0
[main/transactionDownstream] ERROR TransactionSvcDownstream - Error for account
99999999: Unknown
Account Number [MEDIUM]
3.4 Testing Separate Error Handling
Problem
You want to test a service that uses a separate error message with its own DTO.
Solution
Use the YAMLTester to construct test scenarios that should generate posting of the specific error messages.
Discussion
The YAMLTester can be used to test for the presence of a separate error message, the test case will simply check for
this in the output. For the test setup in setup.yaml:
Listing 41. Setup for YAML test

The test input:
Listing 42. Input messages for test

47	of 134 | 3.4 Testing Separate Error Handling
The final test case references an account that has not been setup and so should yield the error message:
Listing 43. Expected output messages from Transaction Service

48	of 134 | 3.4 Testing Separate Error Handling
4. Packaging
Overview
This chapter shows two ways in which a Chronicle Service application can be packaged. Normally a Chronicle Service is
packaged as an executable JAR file, leaving the precise details of how to deploy and run to the customer. However, it is
also possible to package the application as a Docker image.
Recipes
4.1 Packaging a Services Application in a Jar File
You want to package a Chronicle Services Application as an executable JAR file.
4.2 Packaging a Services Application in a Docker Image
You want to package a Chronicle Services application as a Docker container, for more flexibility in deployment to a
cloud environment.
49 of 134 | Overview


4.1 Packaging a Services Application in a Jar File
Problem
You want to package a Chronicle Services Application as an executable JAR file.
Solution
Use the Maven Shade Plugin to create an uber-jar.
Discussion
Chronicle Services does not mandate any special rules concerning the deployment of applications. The standard Maven
build such as that described in the pom.xml file shown earlier will package the application as a jar file. This jar file can
be used to establish a CLASSPATH for executing the application directly using the Main class as an entrypoint.
However, the CLASSPATH also needs to contain all the other libraries that are used by the application - including the
Chronicle libraries that form the Chronicle Services runtime.
A common variant of this is to create a self-contained JAR file that contains the application code and data, plus all of
the dependencies required by the application. Such a jar file is often called an uber-jar, and can be executed directly
without the need to modify any existing CLASSPATH.
The Maven shade plugin supports the construction of an uber-jar for an application.
The term "shade" refers to localised modifications to some package names to avoid
conflicts when multiple versions of the same library are used within the same application.
It is straightforward to add and configure this plugin in the pom.xml file:
Listing 44. POM file extract showing Shade plugin setup
<plugin>
  <groupId>org.apache.maven.plugins</groupId>
  <artifactId>maven-shade-plugin</artifactId>
  <version>3.4.1</version>
  <executions>
    <execution>
      <goals>
        <goal>shade</goal>
      </goals>
      <configuration>
        <shadedArtifactAttached>true</shadedArtifactAttached>
        <transformers>
          <transformer implementation=

"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer">

<mainClass>software.chronicle.services.cookbook.example8a.Mainsoftware.chronicle.
services.cookboo k.example8a.Main</mainClass>

Once added, the "package" goal for the build will generate the uber-jar file and store it in the target directory. Using
the Transaction Service example from the recipes in section 3 as an example: Listing 45. Log excerpt showing shade
plugin operation during build
$ mvn clean package
[INFO] Scanning for projects...
... Normal build and test output ...
[INFO]
[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ chronicle-services-example --
-
[INFO] Building jar: /Users/george/work/Chronicle/Chronicle-Services-
Cookbook/Packaging/target/chronicle-services-example-1.0.0-SNAPSHOT.jar
[INFO]
[INFO] --- maven-shade-plugin:3.4.1:shade (default) @ chronicle-services-
example --[INFO] Including software.chronicle:chronicle-
services:jar:3.23ea37 in the shaded jar.
[INFO] Including net.openhft:chronicle-core:jar:2.23ea34 in the shaded jar.
[INFO] Including net.openhft:posix:jar:2.23ea0 in the shaded jar.
[INFO] Including com.github.jnr:jnr-ffi:jar:2.2.11 in the shaded jar.
[INFO] Including com.github.jnr:jffi:jar:1.3.9 in the shaded jar.
[INFO] Including com.github.jnr:jffi:jar:native:1.3.9 in the shaded jar.
[INFO] Including org.ow2.asm:asm:jar:9.2 in the shaded jar.
[INFO] Including org.ow2.asm:asm-commons:jar:9.2 in the shaded jar.
[INFO] Including org.ow2.asm:asm-analysis:jar:9.2 in the shaded jar.
[INFO] Including org.ow2.asm:asm-tree:jar:9.2 in the shaded jar.
[INFO] Including org.ow2.asm:asm-util:jar:9.2 in the shaded jar.
[INFO] Including com.github.jnr:jnr-a64asm:jar:1.0.0 in the shaded jar.
[INFO] Including com.github.jnr:jnr-x86asm:jar:1.0.2 in the shaded jar.
[INFO] Including com.github.jnr:jnr-constants:jar:0.10.3 in the shaded jar.
[INFO] Including net.openhft:chronicle-analytics:jar:2.23ea1 in the shaded jar.
[INFO] Including net.openhft:chronicle-bytes:jar:2.23ea29 in the shaded jar.
[INFO] Including net.openhft:chronicle-wire:jar:2.23ea38 in the shaded jar.
[INFO] Including net.openhft:compiler:jar:2.23ea0 in the shaded jar.
[INFO] Including net.openhft:chronicle-threads:jar:2.23ea24 in the shaded jar.
[INFO] Including net.openhft:affinity:jar:3.23ea1 in the shaded jar.
[INFO] Including net.openhft:chronicle-queue:jar:5.23ea34 in the shaded jar.
[INFO] Including net.openhft:chronicle-network:jar:2.23ea21 in the shaded jar.
[INFO] Including net.sf.trove4j:core:jar:3.1.0 in the shaded jar.
[INFO] Including software.chronicle:chronicle-queue-enterprise:jar:2.23ea24 in
the shaded jar.
[INFO] Including software.chronicle:chronicle-map-enterprise:jar:2.23ea3 in the
shaded jar.
[INFO] Including net.openhft:chronicle-values:jar:2.23ea2 in the shaded jar.
[INFO] Including com.squareup:javapoet:jar:1.13.0 in the shaded jar.
[INFO] Including net.openhft:chronicle-map:jar:3.23ea4 in the shaded jar.
[INFO] Including net.openhft:chronicle-algorithms:jar:2.23ea3 in the shaded jar.
[INFO] Including net.java.dev.jna:jna:jar:5.8.0 in the shaded jar.
[INFO] Including net.java.dev.jna:jna-platform:jar:5.8.0 in the shaded jar.
[INFO] Including commons-cli:commons-cli:jar:1.4 in the shaded jar.
[INFO] Including org.slf4j:slf4j-simple:jar:1.7.32 in the shaded jar.
[INFO] Including org.slf4j:slf4j-api:jar:1.7.32 in the shaded jar.
[INFO] Dependency-reduced POM written at: /Users/george/work/Chronicle/Chronicle-
Services-
Cookbook/Packaging/dependency-reduced-pom.xml [WARNING] Discovered
module-info.class. Shading will break its strong encapsulation.
[WARNING] Discovered module-info.class. Shading will break its strong
encapsulation.
[WARNING] Discovered module-info.class. Shading will break its strong
encapsulation.
[WARNING] Discovered module-info.class. Shading will break its strong
encapsulation.
[WARNING] Discovered module-info.class. Shading will break its strong
encapsulation.
[WARNING] affinity-3.23ea1.jar, asm-9.2.jar, asm-analysis-9.2.jar, asm-commons-
9.2.jar, asm-tree-
9.2.jar, asm-util-9.2.jar, chronicle-algorithms-2.23ea3.jar, chronicle-analytics-
2.23ea1.jar, chronicle-bytes-2.23ea29.jar, chronicle-core-2.23ea34.jar,
chronicle-map-3.23ea4.jar, chroniclemap-enterprise-2.23ea3.jar, chronicle-
network-2.23ea21.jar, chronicle-queue-5.23ea34.jar, chronicle-queue-enterprise-
2.23ea24.jar, chronicle-services-3.23ea37.jar, chronicle-servicesexample-1.0.0-
SNAPSHOT.jar, chronicle-threads-2.23ea24.jar, chronicle-values-2.23ea2.jar,
chronicle-wire-2.23ea38.jar, commons-cli-1.4.jar, compiler-2.23ea0.jar, core-
3.1.0.jar, javapoet-
1.13.0.jar, jffi-1.3.9-native.jar, jffi-1.3.9.jar, jna-5.8.0.jar, jna-platform-
5.8.0.jar, jnra64asm-1.0.0.jar, jnr-constants-0.10.3.jar, jnr-ffi-2.2.11.jar,
jnr-x86asm-1.0.2.jar, posix-
2.23ea0.jar, slf4j-api-1.7.32.jar, slf4j-simple-1.7.32.jar define 1 overlapping
resource:
[WARNING]   - META-INF/MANIFEST.MF [WARNING] jna-5.8.0.jar, jna-
platform-5.8.0.jar define 3 overlapping resources:
[WARNING]   - META-INF/AL2.0
[WARNING]   - META-INF/LGPL2.1
[WARNING]   - META-INF/LICENSE
[WARNING] maven-shade-plugin has detected that some class files are
[WARNING] present in two or more JARs. When this happens, only
one [WARNING] single version of the class is copied to the
uber jar.
[WARNING] Usually this is not harmful and you can skip these warnings,
[WARNING] otherwise try to manually exclude artifacts based
on [WARNING] mvn dependency:tree -Ddetail=true and the
above output.
[WARNING] See https://maven.apache.org/plugins/maven-shade-
plugin/ [INFO] Attaching shaded artifact.
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  5.827 s
[INFO] Finished at: 2022-12-08T13:49:22Z
[INFO] ------------------------------------------------------------------------
The output shows that the all dependencies, direct and transient, are loaded into the jar file. The plugin ensures that
dependencies are added only once.
After completion, the generated jar files can be seen in the target directory:
Listing 46. Shaded and non-shaded jar files are built
$ ls -l target
total 29520
-rw-r--r--  1 george  staff  14242346  1 Feb 18:04 chronicle-services-cookbook-
example4a-1.0.0-
SNAPSHOT-shaded.jar
-rw-r--r--  1 george  staff     14286  1 Feb 18:04 chronicle-services-cookbook-
example4a-1.0.0-



The basic jar file mentioned above, chronicle-services-cookbook-example4a-1.0.0-SNAPSHOT.jar,
contains the compiled files from the service itself. No dependencies are included.
The shaded jar file, chronicle-services-cookbook-example4a-1.0.0-SNAPSHOT-shaded.jar,
contains the service and all its dependencies. The manifest for the jar file include the main class that will form the
entrypoint of the application. We can run the application directly from the jar file:
$ java -jar target/chronicle-services-cookbook-example4a-1.0.0-
SNAPSHOT-shaded.jar ...
 _____ _                     _      _        _____                 _
/  __ \ |                   (_)    | |      /  ___|               (_)
| /  \/ |__  _ __ ___  _ __  _  ___| | ___  \ `--.  ___ _ ____   ___  ___ ___
___
| |   | '_ \| '__/ _ \| '_ \| |/ __| |/ _ \  `--. \/ _ \ '__\ \ / / |/ __/ _ \/
__|
| \__/\ | | | | | (_) | | | | | (__| |  __/ /\__/ /  __/ |   \ V /| | (_|  __/\__
\
 \____/_| |_|_|  \___/|_| |_|_|\___|_|\___| \____/ \___|_|    \_/
|_|\___\___||___/
:: Chronicle Services ::      (unknown version) Running under OpenJDK
Runtime Environment 1.8.0_345-b01 with 16 processors reported.
Process id:
72429 ...
The output is the same as for the earlier recipes, reflecting the fact that the application itself is unchanged. The
application can now be distributed and deployed as a standalone entity.
4.2 Packaging a Services Application in a Docker Image
Problem
You want to package a Chronicle Services application as a Docker container, for more flexibility in deployment to a
cloud environment.
Solution
Use Maven with the Docker plugin to build and package the image.
Discussion
As more and more applications move to the Cloud, the model for deployment is increasingly based on containers such
as those produced and managed by tools like Docker.
Chronicle Services based applications can be packaged as Docker images, which may then be run in Cloud
Environments. Plugins exist for Maven to support this, and they are easy to incorporate into a build. The build process
for a Docker container will most likely be an extension of that shown in Recipe 4.1, in that they will aim use the shaded
jar file as the simplest means of running the application.
This recipe uses the fabric8 Kubernetes/Docker plugin for Maven to provide the functionality of generating a
Docker image from the build process. This is a very powerful plugin, that is evolving into newer variants managed as
Eclipse JKube, whose focus is on both containerising and deploying to Kubernetes or Openshift. For now, this recipe
demonstrates the simplest usage of the plugin to produce a Docker image that can be run in a Docker runtime
environment.
The plugin may be added to the build:
Listing 47. POM file extract showing inclusion of fabric8 plugin

Where the version is set as a property:
Listing 48. Fabric8 plugin version as a property

Most of the functionality of the plugin and hence the Docker build can be controlled through configuration of the
plugin. Defaults exist for most of the properties, indeed there is no mandatory requirement even to supply a Dockerfile
as the plugin is able to build one for its own use by analysing the project.
The plugin provides a number of goals, but the one that is used to build a Docker image is fabric:build. Default
behaviour expects the presence of an uber-jar file containing the application, so can be combined with the shade
plugin:
Listing 49. Log excerpt from build showing fabric8 plugin
$ mvn clean package fabric8:build
... build shaded jar as before...
[WARNING] See https://maven.apache.org/plugins/maven-shade-
plugin/ [INFO] Attaching shaded artifact.
[INFO]
[INFO] --- fabric8-maven-plugin:4.4.1:build (default-cli) @ chronicle-services-
example ---
[WARNING] F8: Cannot access cluster for detecting mode: connect timed out
[INFO] F8: Running in Kubernetes mode
[INFO] F8: Building Container image with Docker in Kubernetes mode
[WARNING] F8: Cannot access cluster for detecting mode: connect timed out
[WARNING] F8: Cannot access cluster for detecting mode: connect timed out
[INFO] F8: Running generator java-exec
[INFO] F8: java-exec: Using Container image fabric8/java-centos-openjdk8-jdk:1.5
as base /
builder
[WARNING] F8: Cannot access cluster for detecting mode: connect timed out
[WARNING] F8: Cannot access cluster for detecting mode: connect timed out
[INFO] Copying files to /Users/george/work/Chronicle/Chronicle-Services-
Videos/Example5-
Docker/target/docker/chronicle/chronicle-services-example/latest/build/maven
[INFO] Building tar: /Users/george/work/Chronicle/Chronicle-Services-
Videos/Example5-
Docker/target/docker/chronicle/chronicle-services-example/latest/tmp/docker-
build.tar
[INFO] F8: [chronicle/chronicle-services-example:latest] "java-exec": Created
docker-build.tar in
181 milliseconds
[INFO] F8: [chronicle/chronicle-services-example:latest] "java-exec": Built image
sha256:2c42d
[INFO] F8: [chronicle/chronicle-services-example:latest] "java-exec": Removed old
image
sha256:8d08c
[INFO] F8: [chronicle/chronicle-services-example:latest] "java-exec": Tag with
latest
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  57.596 s
[INFO] Finished at: 2022-12-08T14:50:11Z
[INFO] ------------------------------------------------------------------------
By default, the plugin assumes that it is building for a Kubernetes cluster, and
 attempts to query the cluster for confirmation. It is not an error to build without a Kubernetes cluster as is the
case here.
After the build has completed, the image is loaded into the local Docker registry. Configuration options exist to push to
an alternative repository such as Docker Hub. The newly generated image can be seen in this local registry:


Listing 50. Docker image registered in local docker repo
$docker images
REPOSITORY                                        TAG        IMAGE ID
CREATED         SIZE chronicle/chronicle-services-cookbook-example4b   latest
1fdb721fa108   3 minutes ago   471MB ...
Assuming a local Docker runtime is available, the image may then be run:
Listing 51. Output from running the docker image
$ docker run --rm -it chronicle/chronicle-services-
cookbook-example4b ...
 _____ _                     _      _        _____                 _
/  __ \ |                   (_)    | |      /  ___|               (_)
| /  \/ |__  _ __ ___  _ __  _  ___| | ___  \ `--.  ___ _ ____   ___  ___ ___
___
| |   | '_ \| '__/ _ \| '_ \| |/ __| |/ _ \  `--. \/ _ \ '__\ \ / / |/ __/ _ \/
__|
| \__/\ | | | | | (_) | | | | | (__| |  __/ /\__/ /  __/ |   \ V /| | (_|  __/\__
\
 \____/_| |_|_|  \___/|_| |_|_|\___|_|\___| \____/ \___|_|    \_/
|_|\___\___||___/
:: Chronicle Services ::      (unknown version) Running under OpenJDK
Runtime Environment 1.8.0_201-b09 with 4 processors reported.
Process id: unknown
[main/transactionSvc] INFO software.chronicle.services.runner.Runner -
 !ServiceCfg {
  inputs: [
    { input: transactionIn }
  ],
  output: transactionOut,
  implClass: !type
software.chronicle.services.cookbook.example4a.services.TransactionSvcImpl
}
[main/transactionUpstream] INFO
net.openhft.chronicle.bytes.internal.SingleMappedFile - Took 6 ms
to add mapping for /tmp/.time-stamp.jboss.dat
[main/transactionUpstream] INFO software.chronicle.services.runner.Runner -
Starting service
transactionUpstrea
m ...
Console output from the service will be the same as before.
5. Configuration
Overview
Much of the functionality in a Chronicle Services application is controlled through configuration. This may be static, in
that it is specified in a YAML file, conventionally named services.yaml, which is read at application start. Once
read, the data may be accessed from the application and modified during execution although certain changes will not
be possible (such as the classname of a service's implementation).
Recipes
5.1 Using an Alternative Configuration File
Describes how to use a configuration file named something other than services.yaml.
5.2 Parameterising the Configuration File
Shows how to utilise parameters set from outside in a configuration file.
5.3 Runtime Access to Configuration
Shows how an application can access its configuration at when running.
5.4 Using the Configuration File for Application-specific configuration
Shows how to extend the application file to include application specific configuration.
/build/chronicle-services-cookbook/configuration/recipe5-5.html[5.5 Service Configuration]
Shows the different approaches to configure services
57 of 134 | Overview
5.1 Using an Alternative Configuration File
Problem
You want to use an application configuration file named other than services.yaml.
Solution
Pass the name of the configuration file to the call to ThreadRunner.runAll() method.
Discussion
The use of the name services.yaml is a convention and not explicitly required. If you want to maintain different
configurations of the same application, you can do this easily by using separate configuration files.
The method that is normally used to start an application from the main driver class is ThreadRunner.runAll(),
which accepts a pathname to a configuration file as a parameter:
Listing 52. Sample driver class for a Chronicle Services application

Simply changing this parameter will allow a different configuration file to be used.
58 of 134 | 5.1 Using an Alternative Configuration File


5.2 Parameterising the Configuration File
Problem
You want to make the configuration file more general so that different values for properties can be supplied when the
service is run.
Solution
Use system properties and reference them from within the configuration file.
Discussion
The services.yaml file syntax allows you to use system property values, which are then substituted when the
application is run. This allows a certain degree of flexibility in defining configuration properties for the application.
Note however that the file is read only once during startup, so to change the configuration will require the application
to be restarted.
For example, in the Transaction Service application, if you wanted to parameterise the location of the backing files for
the Queues used to communicate between services, this could be done by introducing a system property into the
configuration file:
Listing 53. Excerpt from configuration showing use of properties in config values
!ChronicleServicesCfg {
 queues: {
  transactionIn: { path: ${queue.basedir}/data/transactionIn, sourceId: 1 },
  transactionOut: { path: ${queue.basedir}/data/transactionOut, sourceId: 2 },
  transactionSink: { path: ${queue.basedir}/data/transactionSink, sourceId: 100 },
 },
The term ${queue.basedir} is substituted when the file is read, with the value of the system property
queue.basedir. There are different ways in which this property can be set, these are well documented in Java
documentation.
For example, a command line argument can be used:
Listing 54. Setting the property on running the application

Or the standard Java API:
Listing 55. Setting the property from within the application

59	of 134 | 5.2 Parameterising the Configuration File

An IDE will permit this to be set in the Run Configuration dialog for the application.
60	of 134 | 5.2 Parameterising the Configuration File
5.3 Runtime Access to Configuration
Problem
You want to make the configuration file more general so that different values for properties can be supplied when the
service is run.
Solution
Use system properties and reference them from within the configuration file.
Discussion
The configuration stored in the services.yaml file is read during application startup, and parsed into a set of data
structures that can be accessed in the application. The parsed data is known as the Service Context, it is made available
if a service implements the ServiceContextListener interface, through the serviceContext() method:
Listing 56. Service Implementation with ServiceContextListener included

Listing 57. Method required by ServiceContextListener interface
    @Override
    public void serviceContext( ServiceContext serviceContext ) {
      System.out.println("  ");
      System.out.println("Queues configured for this application");
      serviceContext.runnerCfg().queues().keySet().stream().forEach(q ->
System.out.println("  "
+ q));
      System.out.println("Services configured for this application");
      serviceContext.runnerCfg().services().entrySet().stream().forEach(k ->
showSDetails(k
.getKey(), k.getValue()));
      System.out.println("  ");
    }
The parameter, of type ServiceContext, is populated by the method with the information that was parsed from
the file.
The table below shows the main data available in this structure
Table 1. Methods to access data from the Service Context
Method
Return Type
Description
serviceId()
String
ID of the service
serviceCfg( )
ServiceCfg
Configuration data for the service
61 of 134 | 5.3 Runtime Access to Configuration
Method
Return Type
Description
runnerCfg()
RunnerConfiguration
Overall container for confguration of the application
eventLoop()
EventLoop
Main event loop for the service
The id of the service making the call is returned by the serviceId() method, and its configuration is returned by
the serviceCfg() method. The general configuration for the application is returned by the runnerCfg()
method, which returns an object of type RunnerConfiguration. Some of the methods used to query this
structure are shown below:
Table 2. Table Methods to access data from the Runner Configuration
Method
Return Type
Description
queues()
Map<String,QueueCfg>
Details of the queues used in the application
services()
Map<String,ServiceCfg>
Details of the services used in the application
gc()
GcCfg
Garbage Collection advice for the application
Each of the sections in the services.yaml file is read and parsed into a structure that can be read using the
accessor methods shown here. (The serviceCfg() method from the ServiceContext object is a shortcut to
accessing the calling service's entry from the services() map here).
For an individual service, its configuration can be accessed through the ServiceCfg structure, which contains all of
the information used by Chronicle Services to manage the service. Much of this information is specialised, but we can
see methods that provide access to some of the properties seen in the recipes in this cookbook
Table 3. Table Selected methods from the Service Configuration
Method
Return Type
Description
implClass()
Class<>
Service implementation class
inputs()
List<InputCfg>
List of queues providing input
output()
String
Id of the output queue
configs()
List<String>
List of ids of config queues
serviceConf
ig
Map<String,Object>
Service configuration properties parsed from configuration file
periodicUpd
ateMS()
int
Time interval for periodic update events to the service
heartbeatMS
()
int
Time interval for heartbeat events
startFromSt
rategy()
StartFromStrategy
Strategy for constructing state after (re)start
inputsRepla
yStrategy()
InputsReplayStrategy
Strategy for replaying inputs when (re)constructing state
Having some knowledge of information available through these data structures and methods can be useful when
debugging issues with a service.
62 of 134 | 5.3 Runtime Access to Configuration


5.4 Using the Configuration File for Application-specific
configuration
Problem
You want to supply configuration to a service through its queue inputs
Solution
Define a config queue for the service, and supply the required configuration as messages on this queue.
Discussion
Chronicle Services provides a type of queue known as a config queue. This acts as an input queue to a service, however
on service startup it is guaranteed to be read before any of the normal input queues is read.
This allows messages to be posted on this queue that control the configuration of the service, so that this is completed
before any "business" level messages are processed. It is also possible to pass configuration messages to the service
during normal operation, allowing the configuration to be changed without requiring a service restart.
The config queue is defined in the configuration file:
Listing 58. Configuration File with Config Queue definition
 queues: {
  transactionIn: { path: data/transactionIn, sourceId: 1 },
  transactionOut: { path: data/transactionOut, sourceId: 2 },
  transactionSink: { path: data/transactionSink, sourceId: 100 },
  config: { path: data/transactionConfig, sourceId: 200 }
   }, and attached to the service in the normal
way:
Listing 59. Service configuration with config queue

Notice that, unlike recipe 5.3, the additional service configuration is not now present in the configuration file.
Passing the Configuration to the Service
The configuration queue is read by the service before any other input queues. We can therefore write configuration
messages to this queue as part of the application startup, so that the necessary service configuration is complete
before any other messages are read. This can be done through the application's main() method:
Listing 60. Application startup including posting configuration messages to the config queue
public class Main {     private static final String SERVICES_YAML
= "services.yaml";
    public static void main(String[] args) throws InterruptedException,
IOException {
      final Map<String, Object> configuration = new HashMap<>();
      List<Account> initAccounts = Arrays.asList(
          new Account("currentAccount", 12345678, 100.0),
          new Account("currentAccount", 34343434, 100.0),
          new Account("savingsAccount", 45454545, 200.0)
      );
      configuration.put("accounts", initAccounts);
      QueueCfg config = Marshallable.fromFile(ChronicleServicesCfg.class,
SERVICES_YAML)
          .queues().get("config");
      // write the configuration to the chronicle queue
      single(config.path())
          .sourceId(config.sourceId())
          .build()
          .methodWriter(TransactionConfig.class)
          .accounts(initAccounts);
        ThreadRunner.runAll("services.yaml");
        Thread.sleep(3_000);

} }
Details of the queue are read from the configuration file (this is covered in more detail in recipe 6.1) and then a
message of type accounts is written to the queue. When the service is created and initialised through the call to
ThreadRunner.runall(...), this message will be read and the configuration from the message applied.
An interesting aspect of this approach, as distinct from the earlier approach of having the account objects initialsed via
a message from some upstream service or client, is that the Account DTOs are constructed and initialised using Java
reflection, and there is no need for explicit setter methods, or a specific argument-based constructor.
Running the service
When the service is run, log output will show that the accounts are initialised correctly so that transaction messages
are handled appropriately
Listing 61. Log output showing Transaction Service being initialised
[main/transactionSvc] INFO ...RunLoopControllerMain - running transactionSvc...
[main/transactionSvc] INFO ...TransactionSvcImpl - Adding account 12345678 with
initial balance:
100.0 [main/transactionSvc] INFO ...TransactionSvcImpl - Adding account
34343434 with initial balance:
100.0 [main/transactionSvc] INFO ...TransactionSvcImpl - Adding account
45454545 with initial balance:
200.0
[main/transactionSvc] INFO ...TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionSvc] INFO ...TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
0.0
...
[main/transactionSvc] INFO ...TransactionSvcImpl - Applying DEBIT of 50.0 to
account 34343434
[main/transactionSvc] INFO ...TransactionSvcImpl - Bad transaction: Account
34343434 has
insufficient funds for debit: 50.0 [0.0]
[main/transactionDownstream] INFO ...TransactionSvcDownstream - Success: Balance
of account
34343434 now 0.0
[main/transactionSvc] INFO ...TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545 [main/transactionDownstream] INFO ...TransactionSvcDownstream -
Failed: Insufficient funds 0.0
available for 50.0
[main/transactionSvc] INFO ...TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
210.0
[main/transactionSvc] INFO ...TransactionSvcImpl - Applying CREDIT of 100.0 to
account 12345678
[main/transactionDownstream] INFO ...TransactionSvcDownstream - Success: Balance
of account
45454545 now 210.0
[main/transactionSvc] INFO ...TransactionSvcImpl - Succeeded: Balance of account
12345678 is now
200.0
[main/transactionDownstream] INFO ...TransactionSvcDownstream - Success: Balance
of account
12345678 now 200.0
[main/transactionSvc] INFO ...TransactionSvcImpl - Applying CREDIT of 100.0 to
account 99999999
[main/transactionSvc] ERROR ...TransactionSvcImpl - Unknown account number:
99999999 [main/transactionDownstream] ERROR ...TransactionSvcDownstream - Error
for account 99999999:
Unknown Account Number [MEDIUM]
Notice that the transaction for account 99999999 is rejected as an error, since this account was not configured into the
service.


6. Interacting with External Components
Overview
So far, the applications discussed have been self-contained, in that there is no direct connection with components
from outside the application. However it is often a requirement to gather input data from sources outside the
application and then send messages based on that data to the application. Similarly, there may be a need to send
output messages outside the application to downstream components.
This section discusses how an external component may send messages into a Chronicle Services application from
outside, or receive messages from a Chronicle Services application, or both.
Recipes
6.1 Receiving Events from an External Source
This section explores how to construct and send input messages from outside Chronicle Services into the application.
6.2 Sending Events to an External Sink
This section delves into how to receive messages generated by a Chronicle Services Application in an external
component.
66 of 134 | Overview
6.1 Receiving Events from an External Source
Problem
You want to use information gathered from outside Chronicle Services to construct and send input messages to the
application.
Solution
Obtain a handle to the input Queue of the required service in the application and post messages to it.
Discussion
A Chronicle Service uses Chronicle Queue as the transport for messages into and out of the service. A public API allows
access to post messages to a queue, however it is necessary to know the pathname used by the queue for its backing
storage to set up the handle.
Fortunately this information is available in the application configuration file, so this can be used as part of the
initialisation process.
The Service
For this example, we will use the Transaction Service seen in earlier recipes.
However, all the transaction requests to the service will be issued from an external application that will post them to
the service's input queue. There is no "upstream" service, the Transaction service does not change, but output
messages will still be sent to the downstream service.
The following diagram illustrates the structure of the application:

Note that the transactionSink queue is required as output for the transactionDownstream service, even
although the service does not produce any output.
The External Source Application
Requests are now issued from the SourceMain application, which runs separately from the main service application:
Listing 62. External application posting events into Transaction Service
public class SourceMain {   private static final Logger LOG =
LoggerFactory.getLogger(SourceMain.class);
  static {
    CLASS_ALIASES.addAlias(Transaction.class);
  }
  public static void main(String[] args) throws Exception {
    String configFileName = "services.yaml";
    new SourceMain().run(configFileName);
  }
  private static final Transaction transactionHolder = new Transaction();
  public static void run(String configFile) throws InterruptedException {
    RunnerConfiguration runnerCfg = LoadUtil.loadFromYaml(configFile);
    String svcName = "transactionSvc";
    ServiceCfg serviceCfg = runnerCfg.services().get(svcName);
    String inQId = serviceCfg.inputs().get(0).input();
    String inQPath = runnerCfg.queues().get(inQId).path();
    TransactionSvcIn service = ChronicleQueue.single(inQPath)
        .methodWriter(TransactionSvcIn.class);
    service.accounts(
        Arrays.asList(new Account("currentAccount", 34343434L, 100.0),
            new Account("savingsAccount", 45454545L, 100.0)));
    sendTransaction(service, 34343434, Entry.DEBIT, 50);
    sendTransaction(service, 34343434, Entry.DEBIT, 100);
    sendTransaction(service, 99999999, Entry.CREDIT, 1000);
    Scanner userInput = new Scanner(System.in);
    System.out.print("Enter Account Number: ");
    long accNo = userInput.nextLong();
    System.out.print("Enter [d]ebit or [c]redit: ");
    char trType = userInput.next().charAt(0);
    System.out.print("Enter amount: ");
    double trAmount = userInput.nextDouble();
    sendTransaction(service, accNo, (trType == 'c'  Entry.CREDIT : Entry.DEBIT),
trAmount);
  }
  private static void sendTransaction(TransactionSvcIn service,
                                      long accountNum,
                                      Entry entryType,
                                      double amount) {
    transactionHolder.reset();



1.	The name of the config file for the application, which will have the necessary information about the service's
input queue
2.	A holder class to use for building the transaction, in order to reduce object allocations.
3.	Read and parse the configuration file so queue information can be fetched.
4.	Fetch information about the service we are passing messages to ("transactionSvc"), retrieve the names of the
input queue(s). If there is more than one then use the first named one for this demo. Retrieve the path of the
queue.
5.	Create a handle to the service's input queue.
6.	Create a MethodWriter for the queue, so request messages can be posted to it.
7.	Send a message to create accounts to which transactions will be applied.
8.	Post some request messages to the queue - these should be handled by the service
9.	Gather data interactively, construct a further transaction request message and post it to the queue
10.	Encapsulate the construction and posting of a request message to the service's input queue.
The client simply posts the request messages, and does not receive an indication on whether or not the transaction is
valid or has been handled successfully. All output is posted, by the service, to its output queue, which is read by the
downstream service from where the messages are simply logged.
Running the Applications
The Service is run as before. After initialisation it waits for requests. The external source application can then be
started. Output from the external source application will contain:
Listing 63. Output from external event source application
[main] INFO software.chronicle.services.cookbook.example6a.external.SourceMain -
Sent
transaction: !software.chronicle.services.cookbook.example6a.dto.Transaction {
  accountNumber: 34343434,
  amount: 50.0,
  entry: DEBIT
}
[main] INFO software.chronicle.services.cookbook.example6a.external.SourceMain -
Sent
transaction: !software.chronicle.services.cookbook.example6a.dto.Transaction {
  accountNumber: 34343434,
  amount: 100.0,

You can try this out for yourself by clicking the run button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example6a && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
This simply shows details of the transactions that are posted to the service. The transaction handling and output
messages are seen in the log from the service application:
Listing 64. Log excerpt from Transaction Service showing events from external source being handled
... [main/transactionSvc] INFO TransactionSvcImpl - Adding account 34343434
with initial balance:
100.0 [main/transactionSvc] INFO TransactionSvcImpl - Adding account 45454545
with initial balance:
100.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
50.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionDownstream] INFO TransactionSvcDownstream - Success: Success:
Balance of account
34343434 now 50.0
[main/transactionSvc] INFO TransactionSvcImpl - Bad transaction: Account 34343434
has
insufficient funds for debit: 100.0 [50.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 1000.0 to
account 99999999
[main/transactionDownstream] INFO TransactionSvcDownstream - Failed: Insufficient
funds 50.0
available for 100.0
[main/transactionSvc] ERROR TransactionSvcImpl - Unknown account number: 99999999
[main/transactionDownstream] ERROR TransactionSvcDownstream - Error for account
99999999: Unknown
Account Number [MEDIUM]
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 300.0 to
account 45454545
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
400.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Success: Success:
Balance of account
Log messages from the main service as the transactions are processed can be seen
(main/transactionSvc), together with details of the output messages (main/transactionDownstream).


6.2 Sending Events to an External Sink
Problem
You want to receive messages generated by a Chronicle Services Application in an external component.
Solution
Obtain a handle to the service's output Queue read messages from it.
Discussion
A Chronicle Service uses Chronicle Queue as the transport for messages into and out of the service. A public API allows
access to to a queue for reading or writing messages, however it is necessary to know the pathname used by the
queue for its backing storage to set up the handle. Fortunately this information is available in the services.yaml
file, so this can be used as part of the initialisation process.
The example shown here is based on the Transaction service from earlier recipes. The downstream service has been
removed from the application, and replaced with an external application that reads messages from the service's
output queue and logs them, for information.
The application architecture is shown below:

The External Sink Application
Instead of the Downstream service seen in earlier recipes, output messages are handled in the external application:
SinkMain:
Listing 65. External sink application to consume events from the Transaction Service


1.	The name of the config file for the application, which will have the necessary information about the service's input
queue.
2.	Read and parse the configuration file so queue information can be fetched.
3.	Fetch information about the service from which we are reading messages (transactionSvc), and from that
retrieve the names of the output queue.
4.	Create an instance of a class that implements the transaction service's output API. These are the methods that will
be called when the corresponding messages are detected.
5.	Create a Queue handle for the service's output queue.
6.	Create a MethodReader for the queue, that reads messages from the queue and dispatches them to the handler
defined in <4>.
7.	For demonstration purposes, this application simply reads messages from the queue with the MethodReader,
and handles them.
To keep things simple in the demonstration, there is no lifetime management in this application; it will keep reading
and handling messages until interrupted and terminated.
Running the Applications
The main service should be started first, since it clears out all stale data that may be in the queues following earlier
runs. Diagnostics from the transaction service will show the input messages being received and processed, but not any
output messages:
Listing 66. Log excerpt from Transaction Service showing events being processed
[main/transactionSvc] INFO TransactionSvcImpl - Adding account 34343434 with
initial balance:
100.0 [main/transactionSvc] INFO TransactionSvcImpl - Adding account 45454545
with initial balance:
200.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now 0.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Bad transaction: Account 34343434
has
insufficient funds for debit: 50.0 [0.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
210.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 999999
[main/transactionSvc] ERROR TransactionSvcImpl - Unknown account number: 999999
Run this example by clicking on the button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example6b && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
Notice how the log messages all originate from main/transactionSvc.
Now if the Sink application is run, the output messages from the services can be seen:
Listing 67. Log excerpt from external event sink showing output events from Transaction Service
[main] INFO SinkMain - **OK** Balance of account 34343434 now 0.0
[main] INFO SinkMain - **FAIL** Insufficient funds 0.0 available for 50.0
[main] INFO SinkMain - **OK** Balance of account 45454545 now 210.0
[main] ERROR SinkMain -
Error: !software.chronicle.services.cookbook.example6b.dto.AccountError {
  accountNumber: 999999,
  errorMessage: Unknown Account Number,
  priority: MEDIUM
}
These messages can be correlated with the log messages from the service to see that the applications are functioning
correctly.


7. Additional Features of Services
Overview
This section describes additional functionality that can be added to services for running in the Chronicle Services
framework.
Recipes
7.1 Periodic Events
Shows how a service can be configured to perform processing at regular intervals.
7.2 Filtering Requests Based On DTO Contents
How a service can choose whether or not to handle a request on its input queue, based on data carried in the message
payload.
7.3 Performing Work When a Service is Idle
How a service can perform housekeeping or diagnostic processing when there are no incoming requests for it to
handle.
76 of 134 | Overview
7.1 Periodic Events
Problem
You want to perform actions at regular time intervals.
Solution
Use Periodic Events.
Discussion
It is possible to configure the Chronicle Services runtime to post an event on a service's input queue at regular time
intervals, to allow the service to perform some work such as housekeeping or consolidation and reporting. The event is
known as PeriodicUpdate, and carries a payload of a timestamp at microsecond granularity. To receive the events,
a service should implement the PeriodicUpdateSource interface, and provide the method PeriodicUpdate.
As an example, consider the Transaction Service from earlier recipes. We will change the way the upstream service
sends transaction requests to the main service. Currently, a small group of requests are sent once the upstream service
starts. In this example, the upstream service will subscribe to PeriodicUpdate events, and send transaction
requests when these are received.
Configuration
The modified service will have the following structure:

The time intervals for the generated PeriodicEvents is configured in the service configuration section of the
services.yaml file:
Listing 68. Configuration file showing periodic event configuration

   output: transactionOut,
   implClass: !type
software.chronicle.services.cookbook.example7a.services.TransactionSvcImpl,
  },
  # An upstream service and a downstream service.
  # No input queue for the upstream, and a dummy queue for downstream (we can't
have an empty
output)
  transactionUpstream: {
   inputs: [ upstreamIn ],
   output: transactionIn,
   implClass: !type
software.chronicle.services.cookbook.example7a.services.TransactionSvcUpstream,
   periodicUpdateMS: 2000,          #
   periodicUpdateMSInitial: 1000,   #
  },
  transactionDownstream: {
     inputs: [transactionOut],
     output: downstreamOut,
     implClass: !type
software.chronicle.services.cookbook.example7a.services.TransactionSvcDownstream,
  }
 }
}
1.	Time in milliseconds between the PeriodicEvents being posted.
2.	Time in milliseconds to wait before posting the first PeriodicEvent.
Periodic Events for a service are posted on the service's first named input queue. It is therefore necessary to have at
least one input queue configured for the receiving service. So this example introduces the upstreamIn queue.
If there is more than one input queue for the service, the PeriodicEvents will be posted to the first mentioned queue.
Note that PeriodicEvents are delivered to the service once all other input events have been processed. Therefore the
timing of delivery of these events is not guaranteed, and they should not be used when strict adherence to the time
intervals is critical.
Handling Periodic Events in the Service
The transactionUpstream service should post transaction request messages upon receipt of the
periodicUpdate events. The handler method for these events, periodicUpdate(), must be provided to do
this. So the upstream service implementation will look like this:
Listing 69. Upstream service providing events for the Transaction Service
public class TransactionSvcUpstream implements ServiceLifecycleListener,
PeriodicUpdateSource {
    private static final Logger LOG =
LoggerFactory.getLogger(TransactionSvcUpstream.class);
    private TransactionSvcIn out;
    private final Transaction transaction = new Transaction();
    public TransactionSvcUpstream(TransactionSvcIn out) {
        this.out = out;

The posting of events has been moved from previous recipes, where it was part of the start() method, into the
handler for the Periodic Update events. Based on the configuration shown above, the events will occur every 2
seconds, after an initial delay of 1 second.
Running the Service
The application driver class is written to create and configure the services, then wait for 10 seconds before terminating:
Listing 70. Driver for application

During this time, the upstream service will send blocks of transaction requests every 2 seconds.
You can also see this demo running by clicking the button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example7a && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
Listing 71. Log output from the application

/  __ \ |                   (_)    | |      /  ___|               (_)
| /  \/ |__  _ __ ___  _ __  _  ___| | ___  \ `--.  ___ _ ____   ___  ___ ___
___
| |   | '_ \| '__/ _ \| '_ \| |/ __| |/ _ \  `--. \/ _ \ '__\ \ / / |/ __/ _ \/
__|
| \__/\ | | | | | (_) | | | | | (__| |  __/ /\__/ /  __/ |   \ V /| | (_|  __/\__
\
\____/_| |_|_|  \___/|_| |_|_|\___|_|\___| \____/ \___|_|    \_/
|_|\___\___||___/
:: Chronicle Services ::             (3.23ea37) Running under Java(TM) SE
Runtime Environment 1.8.0_162-b12 with 16 processors reported.
Process id:
5342 ...
[main/transactionSvc] INFO TransactionSvcImpl - Adding account 34343434 with
initial balance:
100.0 [main/transactionSvc] INFO TransactionSvcImpl - Adding account 45454545
with initial balance:
200.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
200.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
150.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Succeeded:
Balance of
account 34343434 now 200.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545 [main/transactionDownstream] INFO TransactionSvcDownstream -
34343434 Succeeded: Balance of
account 34343434 now 150.0
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
210.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Succeeded:
Balance of
account 45454545 now 210.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
250.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Succeeded:
Balance of
account 34343434 now 250.0
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
200.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545 [main/transactionDownstream] INFO TransactionSvcDownstream -
34343434 Succeeded: Balance of
account 34343434 now 200.0
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
220.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Succeeded:
Balance of
account 45454545 now 220.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
300.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Succeeded:
Balance of
account 34343434 now 300.0
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
250.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545


[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Succeeded:
Balance of
account 34343434 now 250.0
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
230.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Succeeded:
Balance of
account 45454545 now 230.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
350.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Succeeded:
Balance of
account 34343434 now 350.0
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
34343434 is now
300.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545 [main/transactionDownstream] INFO TransactionSvcDownstream -
34343434 Succeeded: Balance of
account 34343434 now 300.0
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
240.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Succeeded:
Balance of account 45454545 now 240.0
Process finished with exit code 0
7.2 Filtering Events Based On DTO Contents
Problem
You want to ignore certain events based on the contents of the contained DTO.
Solution
Use the method ignoreMethodBasedOnFirstArg() from the interface MethodFilterOnFirstArg<T>.
Discussion
Sometimes you wish to filter requests being handled by an handler method, in other words ignore the event. There are
various reasons for this, perhaps you have multiple service instances running, and wish to partition the event handling
across these instances based on some criterion.
Chronicle Services provides a mechanism for filtering (ignoring) events based on an argument that is attached to the
request. This could be part of the DTO for the event itself, or something else. The example demonstrated here extends
the Transaction Service application further, by creating two instances of the Transaction Service, each designed to
process requests for account numbers in a specific range.
The diagram below illustrates the overall structure of the application:

Each instance of the transaction service shares the same input queue, but has its own output queue. The instances
read each input message, and decide (based on the filtering logic) whether to handle the message. When an instance
handles a message, it posts the output to its output queue. The downstream service has both output queues as its
inputs, reads the messages and logs them (as in earlier recipes).
API to Support Filtering
In order to implement message filtering, the API for the Transaction Service is modified:
Listing 72. Input interface for Transaction Service


The method to post the request requires an additional argument, which is used in the filtering checks. As mentioned
above, filtering is carried out based on the account number, so that is used as the initial argument. The DTO still needs
to be passed as the second argument.
Service Implementation
To provide the filtering behaviour, the service implementation is required to implement the interface
MethodFilterOnFirstArg<T>, where T is the type of the value that is being checked. In this case the
transaction service implementation class will be:
Listing 73. Transaction Service Implementation class with Method Filter interface

The interface requires a method to be supplied to perform the filtering:
Listing 74. Method to perform filtering of incoming events

The method should examine the value of the firstArg parameter, and return:
	true if the message is to be ignored
	false if the message is to be processed
Otherwise, the service implementation is as before.
Service Configuration
Each instance of the service should handle requests for account numbers in a specific range. The bounds of the range
for each service are supplied as configuration parameters, so the services.yaml file needs to have these added:
1. Configuration showing multiple Transaction Service instances
!ChronicleServicesCfg {
 queues: {
  transactionIn: { path: data/transactionIn, sourceId: 1 },
  transactionOut1: { path: data/transactionOut1, sourceId: 2 },
  transactionOut2: { path: data/transactionOut2, sourceId: 3 },
  downstreamOut: { path: data/downstreamOut, sourceId: 100 },
 },
 services: {
  transactionSvc1: {
    inputs: [ transactionIn ],
    output: transactionOut1,
    implClass: !type
software.chronicle.services.cookbook.example7b.services.TransactionSvcImpl,
    account: [ !Account { name: "currentAccount1", accountNumber: 01234567,
balance: 100.0 },
               !Account { name: "savingsAccount2", accountNumber: 12345678,
balance: 200.0 },
               !Account { name: "savingsAccount3", accountNumber: 45678901,
balance: 300.0 } ],
    acceptFrom: 00000000,
    acceptTo: 49999999,
  },
  transactionSvc2: {
    inputs: [ transactionIn ],
    output: transactionOut2,
    implClass: !type
software.chronicle.services.cookbook.example7b.services.TransactionSvcImpl,
    account: [ !Account { name: "currentAccount4", accountNumber: 78901234,
balance: 100.0 },
               !Account { name: "savingsAccount5", accountNumber: 90123456,
balance: 200.0 } ],
    acceptFrom: 50000000,
    acceptTo: 99999999,
  },
  transactionUpstream: {
   inputs: [ ],
   output: transactionIn,
   implClass: !type
software.chronicle.services.cookbook.example7b.services.TransactionSvcUpstream,
  },
  transactionDownstream: {
    inputs: [transactionOut1, transactionOut2],
    output: downstreamOut,
    implClass: !type
software.chronicle.services.cookbook.example7b.services.TransactionSvcDownstream,
  }
 }
}
The configuration information is read and processed during service initialisation using the serviceContext()
method shown in earlier recipes:
Listing 75. Applying instance specific configuration for a Transaction Service Instance
  @Override
  public void serviceContext(ServiceContext serviceContext) {
    // Set up the accounts from the config in services yaml
    accounts((List<Account>)
serviceContext.serviceCfg().serviceConfig().get("account"));
    // Set up the range of account numbers we will handle in this instance
    this.instanceName = serviceContext.serviceId();

    this.acceptFrom = (Long)
serviceContext.serviceCfg().serviceConfig().get("acceptFrom");
    this.acceptTo = (Long)
serviceContext.serviceCfg().serviceConfig().get("acceptTo");
    LOG.info("{} accepting from {} to {}", instanceName, acceptFrom, acceptTo);



1.	Set up some initial accounts, for demo purposes.
2.	Extract the name of the service, for diagnostic messages.
3.	Extract the range of account numbers to be handled by this service instance.
Running the Service
Transactions for the service are posted by the upstream service as in earlier recipes.
See this example by running the example below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example7b && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
Listing 76. Transaction events sent by upstream service
    transaction.accountNumber(12345678).entry(Entry.DEBIT).amount(500);
    out.transaction(transaction.accountNumber(), transaction);
    transaction.accountNumber(45678901).entry(Entry.CREDIT).amount(75);
    out.transaction(transaction.accountNumber(), transaction);
    transaction.accountNumber(90123456).entry(Entry.CREDIT).amount(10);
    out.transaction(transaction.accountNumber(), transaction);
    transaction.accountNumber(99999999).entry(Entry.CREDIT).amount(1000);
    out.transaction(transaction.accountNumber(), transaction);
Messages logged by the downstream service show which instance of the service processed each transaction.
Listing 77. Log output showing events and handling instances
...
[main/transactionDownstream] INFO TransactionSvcDownstream - *Success*  Account:
90123456 Balance
of account 90123456 now 210.0 [transactionSvc2]
[main/transactionDownstream] INFO ransactionSvcDownstream - *Failed*  Account:
12345678
Insufficient funds 200.0 available for 500.0 [transactionSvc1]
[main/transactionDownstream] ERROR TransactionSvcDownstream - Error for account
99999999: Unknown
Account Number [transactionSvc2] [MEDIUM]
[main/transactionDownstream] INFO TransactionSvcDownstream - *Success*  Account:
45678901 Balance
of account 45678901 now 375.0
[transactionSvc1] ...
From here we can see that messages are filtered correctly, even in the case where the account number is invalid.
7.3 Performing Work When a Service is Idle
Problem
You want to arrange for work to be done when a service is not handling incoming requests.
Solution
Implement this work as a PollingUpdateSource.
Discussion
Regular tasks such as housekeeping or diagnostics are not always best performed on the basis of time intervals, as is
the case with Periodic Updates in Chronicle Services. It is often more appropriate to have a way of scheduling tasks on
the basis of how loaded a service may be with incoming requests, especially the load is subject to bursts of requests
interspersed with periods of relative inactivity.
Chronicle Services offers the PollingUpdate facility to allow for this to be achieved.
When a service implements the PollingUpdateSource interface, it will be integrated with this facility. The
interface requires the provision of two methods to define how this integration is to be performed:
public boolean publishUpdateOnIdle()
called when the service is "idle" - i.e. there are no incoming requests to be handled by the service, return true when
there is work to do and false when not.
public void pollingUpdate(long currentTime)
defines the work to be done when publishUpdateOnIdle() returns true
As an example, consider the transaction service application:

The Periodic Update events cause the upstream service to post transaction requests at regular intervals; these are
processed and their output posted to the downstream service, which logs details.
We can modify the transaction service so that, when there are no incoming requests to process, it will publish a
summary of all the accounts that it is currently managing. If there have not been any changes to any of the accounts,
then nothing will be published (for example, transactions may have been rejected by the service).
The required changes to the transaction service are shown below.
First, it is necessary to change the API so that the service implementation is seen to implement the
PollingUpdateSource interface:

Then the functionality is added to the implementation class:
public class TransactionSvcImpl implements TransactionSvcIn
{   private static Logger LOG =
LoggerFactory.getLogger(TransactionSvcImpl.class);
  static {
    CLASS_ALIASES.addAlias(Account.class);
  }
  private final TransactionSvcOut out;
  private final Map<Long, Account> balanceByAccount = new HashMap<>();
  private final List<Account> allAccounts = new ArrayList<>();
  private volatile boolean accountsUpdated = true;
  private OnTransaction onTransaction = new OnTransaction();
  private AccountError accountError = new AccountError();
  public TransactionSvcImpl(TransactionSvcOut out) {
    this.out = out;
  }
  @Override
  public void transaction(Transaction transaction) {
    LOG.info("Applying {} of {} to account {}", transaction.entry(),
transaction.amount(),
transaction.accountNumber());
    Account account = balanceByAccount.get(transaction.accountNumber());
    if (account == null) {
      LOG.error("Unknown account number: {}", transaction.accountNumber());
      accountError.reset();
      accountError.accountNumber(transaction.accountNumber())
          .errorMessage("Unknown Account Number")
          .priority(Priority.MEDIUM);
      out.accountError(accountError);
      return;
    }
    onTransaction.reset();
    transaction.copyTo(onTransaction);
    if ((transaction.entry() == Entry.DEBIT) && (account.balance() <
transaction.amount())) {
      out.onTransaction(onTransaction.success(false).reason("Insufficient funds "
+ account
.balance() + " available for " + transaction.amount()));



The behaviour we are implementing is that, whenever the service is idle and the balance of one or more accounts has
changed, then a list of accounts is published to the service output whenever the service is idle.
A global flag, accountsUpdated, indicates that there have been changes made since the accounts list was last
published. This flag is initialised to false, updated to true when a transaction is successfully applied to one of the
accounts, and reset to false again after the accounts list is posted. The checking callback method
publishUpdateOnIdle() simply returns the value of this flag.
If a polling update is to be performed, then a list of all accounts is constructed and posted as the payload of the
accountBalances method. The downstream service will log a summary of this list in its message handler.


Running the Service
The demo application is run with two accounts, both initialised with a balance of 200. Repeated debit transactions will
reduce these balances until they reach a value that will not allow the debit, subsequent attempts to debit are refused.
The log will show this happening:
Listing 78. Log output showing balance updates
[main/transactionSvc] INFO TransactionSvcImpl - Adding account 34343434 with
initial balance:
200.0 [main/transactionSvc] INFO TransactionSvcImpl - Adding account 45454545
with initial balance:
200.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Account Balances:
[45454545: 200.0,
34343434: 200.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 60.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 40.0 to account
45454545
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Succeeded:
Balance of
account 34343434 now 140.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Succeeded:
Balance of
account 45454545 now 160.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Account Balances:
[45454545: 160.0,
34343434: 140.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 60.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 40.0 to account
45454545
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Succeeded:
Balance of
account 34343434 now 80.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Succeeded:
Balance of
account 45454545 now 120.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Account Balances:
[45454545: 120.0,
34343434:
80.0] ...
To see this example running, click on the button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example7c && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
The account lists output from the messages initiated by the PollingUpdates can be seen. Eventually the account
balances reach a state where the transactions are rejected, after that point there is no change to the account balances
and so the account list updates do not occur.
Listing 79. Log output showing failed transactions eventually preventing balance updates so balances not printed
...
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 60.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 40.0 to account
45454545
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Failed:
Insufficient funds
20.0 available for 60.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Succeeded:
Balance of
account 45454545 now 0.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Account Balances:
[45454545: 0.0,
34343434: 20.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 60.0 to account
34343434
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 40.0 to account
45454545
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Failed:
Insufficient funds
20.0 available for 60.0
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Failed:
Insufficient funds
0.0 available for 40.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 60.0 to account
34343434
[main/transactionDownstream] INFO TransactionSvcDownstream - 34343434 Failed:
Insufficient funds
20.0 available for 60.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 40.0 to account
45454545
[main/transactionDownstream] INFO TransactionSvcDownstream - 45454545 Failed:
Insufficient funds
0.0 available for 40.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 60.0 to account
34343434
[main/transactionDownstream] INFO sTransactionSvcDownstream - 34343434 Failed:
Insufficient funds
20.0 available for 60.0
...


8. Managing State in Chronicle Services
Overview
In applications built using Chronicle Services, the ideal architecture is one where components minimise their
dependence on state, especially mutable state. A stateless approach is something that can be introduced at the design
level, in terms of the messages that are used to communicate between the components, or at the implementation
level in choice of algorithms or implementation strategies.
Chronicle Services applications are built using Chronicle Queue as the underlying message transport. Chronicle Queue
offers an immutable, persistent store of events/messages whose size is limited only to the amount of persistent
storage available. In the majority of service components, state is typically constructed cumulatively based on the
results of handling events over time. Given that Chronicle Queue provides a reliable platform for holding these events,
it should be possible to use them to recreate the state of a service if it were to stop, either deliberately or through a
problem, and start again. All that is needed is to replay the events that built the state.
In practice, however, it is not always necessary to do this (the service may be stateless), or practical (in some cases
there may be very large numbers of events - one deployed service has a queue that is measured in Terabytes of
memory). There are therefore a number of different approaches that can be taken when it comes to setting up
necessary state in a service when it (re)starts.
Recipes
8.1 Initializing State from a Single Input Queue
Demonstrates how to initialize the state of a service with a single input queue following a (re)start.
8.2 Initializing State from Multiple Input Queues
This section delves into initialising the state of a service with multiple input queues following a (re)start.
8.3 Initializing State from the Output Queue
Explores initialising the state of a service without having to replay all significant input messages.
91 of 134 | Overview
8.1 Initializing State from a Single Input Queue
Problem
You want to initialize the state of a service with a single input queue following a (re)start by replaying messages from
the input queue.
Solution
Configure the service with startFromStrategy set to START and inputsReplayStrategy set to INPUTS.
Discussion
This recipe is based on a simple application, a Portfolio Manager that maintains a list of Foreign Exchange Positions,
updated by Trades.
The following diagram shows the structure of the application:

The main service manages a list of Positions, which are accumulated by processing Trades from a queue known as
"trades-out". Trades are posted onto this queue by an external application. On receipt of a message indicating a new
trade, the service updates the relevant position and posts the resulting positions to an output queue, which is read and
displayed by a second external application.
Configuring the Service
The application is configured in the services.yaml file:
Listing 80. Configuration of the application
# uses schema from https://github.com/ChronicleEnterprise/Chronicle-Services-

The remaining components are not managed by Chronicle Services, and so do not appear in the file.
From the perspective of state management, there are two important properties configured for the service, namely
startFromStrategy and inputsReplyStrategy. Taken together, these instruct the service to construct its
state by replaying all events in the input queue. Essentially this is running the service from scratch all over again.
Running the Application
Details of how to run the application can be found below.
To run a demo of this, please click on the 'run' button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example8a && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
There are three components that need to be started.
First, the Position service is started. On a clean start, i.e. one where the trades-out queue does not exist, or
where there are no pre-existing trades in the queue, it performs a standard Chronicle Services initialization sequence,
and waits for events to appear on its input queue.
Next, the Tailer component is started. This is not a Chronicle Services application, although the functionality is
actually part of the Chronicle Queue package. It will initialize itself, wait for messages to be posted on the
position-out queue and display them on its standard output.
Thirdly, the TradeEntry component is started. This is also external to the Chronicle Services framework. Its job is to
allow a user to manually enter details of a trade, which is then posted to the trades-out queue from where it is
read by the Position Service. As an example:
Listing 81. Example interaction with the TradeEntry component


Once the details are entered, the trade is posted and the application displays details. For example, the Position Service
log shows:
Listing 82. Output from the main service in the application

which is a log of the incoming trade, and the position details posted to the output queue. At the same time, the
Tailer application shows:
Listing 83. Output showing the tail of the service's output queue


which is a log of the latest information contained on the position-out queue.
If a second trade is entered: Listing 84.
Second trade entered

then the logged output will reflect this. First the Position service: Listing 85.
Output from the service reflecting the second trade

and then the Tailer output:
Listing 86. Output from the queue Tailer showing cumulative positions


(Re)creating State after (Re)start
As shown above, when the Positions Service performs a "clean" start, it is initialised with no information about
Positions. Therefore, if the service were to stop or crash, any current Positions information will be lost when the
service restarted.
With the confguration shown above, when the service starts it will replay all events on its input queue, recreating the
state as it was when the service stopped. Of course, no output messages will be posted as a result of this replaying.
The log messages from the service on startup will show this: Listing 87. Log
messages from the service following restart
...
[software.chronicle.services.demo.RunService/positionSvc] INFO InputsController -
#InputQueues=1
[software.chronicle.services.demo.RunService/positionSvc] INFO InputsController -
building
queue=data/trades-out
[software.chronicle.services.demo.RunService/positionSvc] INFO InputsController -
Setting up
queue reader for data/trades-out START
[software.chronicle.services.demo.RunService/positionSvc] INFO Runner -
replayInputQueuesHistory
begin
[software.chronicle.services.demo.RunService/positionSvc] INFO
PositionServiceImpl - Processing
Trade: !Trade {
  eventId: "",
  eventTime: 0,
  ticker: AUDUSD,
  buy: true,
  qty: 100000,
  price: 0.7777



The log messages show the replaying of the (2) trade messages that were entered during the previous session. It is
possible to verify that the state has correctly been recreated by entering a further trade:
Listing 88. Adding a further trade

Now, checking the log output from the Tailer, we can see that the final Position report shows:
Listing 89. Tailer output reflecting cumulative positions

The quality of AUSUSD in the position is 2000, showing that the most recent trade was added to the previous position
for AUDUSD.
8.2 Initializing State from Multiple Input Queues
Problem
You want to initialise the state of a service with multiple input queues following a (re)start by replaying messages from
the input queues.
Solution
Configure the service with startFromStrategy set to START and inputsReplayStrategy set to OUTPUT.
Discussion
When the service reads its input from a single input queue, the approach described in recipe 8.1 is ideal, since all
messages are processed in order, although not in "real-time" (ie.without the delays between messages). When the
service reads from multiple queues, however, it is important to note that the ordering of messages across queues is
not guaranteed.
In this recipe we will look at a slightly modified version of the application shown in recipe 8.1:

The Position service now has two input queues. The first, position-in, will receive PeriodicUpdate events at
a configurable interval. The second, receives messages posted by the TradeEntry component when a new trade is
posted, as in receipe 8.1. The Position Service will post position information to the output queue when a trade is
received, and also on every third PeriodicUpdate event.
While it may seem that it is possible to recreate state by configuring the service to replay using the INPUTS value for
inputsReplayStrategy, in practice this is not the recommended approach. Indeed a warning message is printed
if this is done:
[main/positionSvc] WARN Runner - Replaying using InputsReplayStrategy.INPUTS with
more than one


input may lead to non-deterministic results. Suggest to use OUTPUT
The reason for this is that Chronicle Services does not guarantee the order in which multiple input queues are read
during replay. Events that alter the state in a cumulative fashion may be read in a different order from that in which
they originally occurred. If this happens then the state after replay may not be the same as that when the service
stopped.
The warning message does suggest what the configuration should be to avoid this happening - the
inputReplayStrategy property should be set to OUTPUT:
# uses schema from https://github.com/ChronicleEnterprise/Chronicle-Services-
Demo/blob/master/docs/services.schema.json
!ChronicleServicesCfg {
  queues: {
    position-in: { path: data/position-in, sourceId: 1 },
    position-out: { path: data/position-out, sourceId: 2 },
    trades-out: { path: data/trades-out, sourceId: 3 },
  },
  services: {
    positionSvc: {
      inputs: [ position-in, trades-out],
      output: position-out,
      startFromStrategy: START,
      inputsReplayStrategy: OUTPUT,
      implClass: !type
software.chronicle.services.cookbook.example8b.services.impl.PositionServiceImpl,
      periodicUpdateMS: 5000,
    },
  }
}
This is based on the assumption that any event that, when processed, causes the service state to change, will result in
a message being posted to the output queue. Event history metadata posted to the output queue allows these events
to be correlated with input events, and this lets Chronicle Services know which events should be replayed - if an input
event cannot be connected to an output event, it is considered to be an insignificant event, will be skipped during
replay.
Running the Application
Details of how to run the application can be found below.
To run a demo, please click on the 'run' button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example8b && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
After starting the three services (details in Recipe 8.1), two trades are entered.
Shown below is an extract from the logs of the Position Service:
Listing 90. Position Service log messages
[software.chronicle...] INFO RunLoopControllerMain - running positionSvc...
...
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event

[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting Position
Summary
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Processing
Trade: !Trade {
  eventId: "",
  eventTime: 0,
  ticker: AUDUSD,
  buy: true,
  qty: 100000,
  price: 0.7777
}
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting Position
Summary
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting Position
Summary
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Processing
Trade: !Trade {
  eventId: "",
  eventTime: 0,
  ticker: EURUSD,
  buy: true,
  qty: 100000,
  price: 1.2222
}
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting Position
Summary [...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update
Event
1.	Receipt of a periodicUpdate event, but without posting the position summary.
2.	Posting position summary as a result of receiving the PeriodicUpdate event. shown on the previous line (ie on
every third periodicUpdate).
3.	Receipt of a trade, entered through the TradeEntry component.
4.	Posting position summary after processing a received trade as indicated by the previous log message.
The Tailer shows the posted positions:
Listing 91. Output from the queue Tailer component showing cumulative positions





1.	No positions, this message was posted before the first trade was entered.
2.	After the first trade.
3.	After the second trade.
Replay following service restart
When the Position Service is stopped and started again, the logs show the replaying of messages to rebuild the
state. No output messages will be posted as a result of this replaying:
Listing 92. Log output from Position Service following restart
[...demo.RunService/positionSvc] INFO Runner - replayInputQueuesHistory begin
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Processing
Trade: !Trade {
  eventId: "",
  eventTime: 0,
  ticker: AUDUSD,
  buy: true,
  qty: 100000,
  price: 0.7777
}
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting Position
Summary
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Processing
Trade: !Trade {
  eventId: "",
  eventTime: 0,
  ticker: EURUSD,
  buy: true,
  qty: 100000,
  price: 1.2222
}
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting Position
Summary
[...demo.RunService/positionSvc] INFO Runner -
replayInputQueuesFromOutputQueueHistory replayed=4
[...demo.RunService/positionSvc] INFO Runner - replayInputQueuesHistory end
replayedCount=4
replayError=false
[...demo.RunService/positionSvc] INFO PeriodicEventController - Writing periodic
updates to queue
data/position-in [...demo.RunService/positionSvc] INFO Runner -
runInitializationComplete [...demo.RunService/positionSvc] INFO
RunLoopControllerMain - running positionSvc...
The amount of events replayed is less than the amount that occurred in the original run of the service. However, only
every third periodicUpdate event resulted in the position summary being posted to the output queue so only
these are replayed.
Output from the Tailer process verifies that the state has been recreated correctly:
Listing 93. Output from the queue Tailer component showing correctly reconstructed position data


1.	Displayed following the position service restart, shows the state correctly recreated.
2.	Displayed following the submission of a further trade.
Points To Note
The approach described here depends on the distinction between significant and insignificant events. Significant
events are those that cause a service's state to be updated. As already mentioned, the expectation is that all significant
events will generate output messages. Insignificant events may generate output messages, meaning that they would
be replayed using this configuration, however this will not affect the recreated state.
For example, in the example shown here, periodicUpdate events can trigger the posting of an informational
message but do not change the service's state. In the example, only every third periodicUpdate event causes the
posting of this message, meaning that 2 out of every 3 of these input events is ignored.
Replaying an insignificant event is not an issue, other than that the replay may include needless work. Some care
should be taken when defining the events and their flow to keep this situation from not occurring.
If the inputReplayStrategy is set to OUTPUT_ALL, then all events, significant and insignificant, will be replayed,
although the relative ordering of insignificant events may be altered between significant events.
If a service is invoked with the system property replayOutput set (e.g. -DreplayOutput), then the
startFromStrategy and inputsReplayStrategy configuration will be overridden, and set to START and
OUTPUT respectively.


8.3 Initializing State from the Output Queue
Problem
You want to initialise the state of a service without having to replay all significant input messages.
Solution
Design the service to include all relevant state in output messages, and configure replay options accordingly.
Discussion
The overhead of initialising state by replaying input messages has the potential to be significant in the case of long-
running, high throughput services. However, often services are designed to include a significant amount of state
information in their output messages. This provides an opportunity to take a different approach to initialising state. It
considers output messages as a form of snapshot of state, perhaps partial but often complete.
In this approach, the replay reads messages from the output queue in reverse order, i.e. latest message first, and
invokes a specific method in the service to use these messages to recreate state. The service can stop this process once
it is satisfied that all state has been recreated.
If we look at the Position Service application again, although slightly modified, we can see how this would work:

The main functionality of the application is the same as for Recipe 8.2. The difference here is that there is a path for
the position service to read the output events from the position-out queue during initialisation, in order to
recreate its state.
The messages on this queue are posted either when a trade is processed, or on every third periodic update event. The
position service needs to be updated to include a handler for these messages, although this handler will only be
invoked during initialisation. The handler must use the data in the message to update the internal data structures that
contain the state used by the service.
In this example, each message contains a complete summary of the positions held by the service, so all that is needed
to create the complete state when the service stopped is the last message posted to the queue. The service must also
provide a callback method that is used to indicate whether the replaying of messages from the output queue is to be
stopped, in this case the service should only process one message (the last one posted), and so this method will return
true on its first invocation.
The configuration of the application to enable this form of replay is:
Listing 94. Configuration for state replay using output queue

The value OUTPUT_REVERSE indicates that this service will read events in most-recent-first order from its output
queue and replay them until satisfied that its state has been completely reconstructed. Setting the startFromStrategy
to LAST_WRITTEN is an instruction that once initialised, the service should begin processing input events that arrived
after the last event that on the output queue (which would be the first event that it reapplied to rebuild state). In
some cases, this value can be set to END to begin looking at events that arrive only after initialisation is complete.
Changes to the Service Implementation
(Re)building state from output messages requires some changes to be made to the service implementation. The
implementation class must be able to handle output events as well as input events. It must also contain logic to
determine whether the state has been completely reconstituted, as the output messages may not contain all state.
This can be done by extending the "normal" service implementation class and introducing the additional functionality.
This is shown in the following class:

1.	PositionsListener specifies that the service can handle positions() events,
OutputReverseListener specifies that the class has the stateReplayed() method to determine
whether replay of output messages should stop.
2.	Populate the main positions structure with the information that was published in the event that is being replayed
here.
3.	In this case, the output events we are replaying contain all the state, so only one is required.
Running the Service
Details of how to run the service can be found below.
To see a demo, click on the 'run' button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example8c && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
For this demo, the Position service is started and a single trade is entered using the TradeEntry component. Excerpts
from the service logs show this happening:
Listing 95. Log messages from Position Service
[...demo.RunService/positionSvc] INFO RunLoopControllerMain - running
positionSvc... ...
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting
Position Summary ...


[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Processing
Trade: !Trade {
  eventId: "",
  eventTime: 0,
  ticker: AUDUSD,
  buy: true,
  qty: 100000,
  price: 0.7777
}
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting Position
Summary
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Posting Position
Summary
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Periodic Update Event
The Tailer component shows the events posted to the output queue:
Listing 96. Output from queue Tailer process showing cumulative position data


1.	Posted in response to the periodicUpdate event at the service and shows no positions.
2.	Posted in response to the processing of the trade, and shows the resulting position.
Replay Following Restart
If the Position Service is stopped and then restarted, log messages will show the replay of the output queue to recreate
state:
Listing 97. Log messages from Position Service following restart
...
[...demo.RunService/positionSvc] INFO Runner - replayInputQueuesHistory begin
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Replaying event from
output
[...demo.RunService/positionSvc] INFO PositionServiceImpl - Checking if
replay complete: true ... [...demo.RunService/positionSvc] INFO
RunLoopControllerMain - running positionSvc... ...
If a new event is posted, then the positions are updated correctly and posted to the output queue:
Listing 98. Output from Tailer process following service restart

1.	Positions posted due to first PeriodicUpdate event after restarting.
2.	Positions posted after new trade issued.


9. Diagnostics and Monitoring
Overview
It is often useful to be able to see what is happening "behind the scenes" in a Chronicle Services application, especially
while diagnosing issues. The recipes shown here demonstrate how to discover more about how messages pass
through an application.
Recipes
9.1 Finding Out Which Service Posted a Message
Discovering which service posted a message.
9.2 Tracing the Flow of a Message Through an Application
Obtaining the path of a message through upstream services in an application.
9.3 Displaying Latencies in Message Processing
How to discover timings related to a message passing through an application.
9.4 Simple Heartbeat Monitoring
How to establish simple heartbeats between two services.
9.5 Using Heartbeats to Monitor Service Availability
How to determine availability of services and their dependencies using heartbeats.
112 of 134 | Overview
9.1 Finding out which service posted a message
Problem
You want to find out which service posted the message being processed in a service.
Solution
Use MessageHistory and application metadata.
Discussion
There are different aspects to this problem, in this recipe we will look at the simplest, namely discovering the name of
the immediately upstream service that posted the message currently being processed.
In order to do this, we will look at the MessageHistory - metadata that is posted to the Chronicle Queue carrying
the message by the Chronicle Services runtime. This currently provides information about the queue from which the
message was read. We also use a set of utility classes provided by Chronicle Services that assicates this queue with the
service for which this carries output messages.
To illustrate this, we will use them "multi-instance" Transaction Service application described in recipe 7.2.
The application structure is shown below:

Our focus is on the downstream service, transactionDownstream, which receives output from all instances of
the main transaction service. Each instance of the service outputs to its own queue, and the job of the downstream
service is to consolidate the messages into a single output queuee and pass them on (in this case all that happens is
that the messages are logged).
In the previous example, the output messages from the transaction service instances included the name of the sending
service instance. This may not always be possible, and in this example we remove the need to include the sending
instance name from the actual output. Instead, we use MessageHistory and application metadata to discover the
sending instance. From a design perspective, it is more desirable to take this approach as it is up to the message
receiver to decide whether the information is needed, and recover it, separately from the application protocol. No
changes are requred to the sending service to allow this to be done.
Changes to the Receiving Service
To gain access to the metadata necessary to decode the MessageHistory, the receiving service uses the mechanism
described in recipe 5.3 to access the main configuration, namely implementing the ServiceContextListener
interface:
Listing 99. Downstream service implementing ServiceContextListener for access to configuration

The configuration is stored in a RunnerConfiguration object:
Listing 100. Capturing the application configuration data

Now we can use methods from the package software.chronicle.services.tools, which is part of the core
Chronicle Services library, to encapsulate the logic to interpret MessageHistory in the context of this metadata in
the a method:
Listing 101. Using metadata to extract sending service information from the message

1.	Retrieve the MessageHistory metadata that was posted alongside the message DTO, and extract the sourceID
of the queue from which it was read.
2.	Fetch the configuration of the queue.
3.	Find the service that uses that queue as an output. Requires a File object representing the queue's location in
the filesystem, and the overall application configuration. Return the service "linkage" information.
4.	The toString() method on the service link object returns the service's name as found in the application
configuration.
The above method can be called in any message handlers, to return the name of the upstream service. For example:
Listing 102. Handler for messages from the Transaction Service
  @Override
  public void onTransaction(OnTransaction onTransaction) {
    if (onTransaction.success()) {
      LOG.info("[{}] *Success*  Account: {} {}", upstreamService(), onTransaction.
accountNumber(), onTransaction.reason());
    } else {
      LOG.info("[{}] *Failed*  Account: {} {}", upstreamService(),
onTransaction.accountNumber(),
onTransaction.reason());
    }
  }
Log messages now display the sending service instance. You can also see this running by clicking the 'run' button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example9a && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
[main/transactionDownstream] INFO TransactionSvcDownstream - [transactionSvc1]
*Failed*  Account:
12345678 Insufficient funds 200.0 available for 500.0
[main/transactionDownstream] INFO TransactionSvcDownstream - [transactionSvc2]
*Success*
Account: 90123456 Balance of account 90123456 now 210.0
[main/transactionDownstream] INFO TransactionSvcDownstream - [transactionSvc1]
*Success*
Account: 45678901 Balance of account 45678901 now 375.0
[main/transactionDownstream] ERROR TransactionSvcDownstream - [transactionSvc2]
Error for account
99999999: Unknown Account Number [MEDIUM]


9.2 Tracing the flow of a message through an application
Recipe 9.1 allows you to find out the immediate predecessor of the calling service in the application. Sometimes it is
desirable to be able to trace a message from its first occurrence (effectively its ingress) in the application, seeing all
stages through which it has passed.
Problem
You want to display the complete trace of an event through the application.
Solution
Use MessageHistory, connecting back to previous messages through the data held there.
Discussion
The MessageHistory object has details of one stage of an event's journey through the application. Enough
information is held in the object to allow reading the MessageHistory of the previous stage, and this allows the
construction of a chain of objects, so it is possible to see the complete path of the event through the application.
A low level API is available for reading and writing from the Queues where the history information has been written,
and for presenting the history mechanism effectively.
A Demo Application
We can examine this capability using a demo application, whose structure is shown here:

The application configuration is shown here:
The configuration is shown here:
Listing 103. Application configuration
# uses schema from https://github.com/ChronicleEnterprise/Chronicle-
ServicesDemo/blob/master/docs/services.schema.json
!ChronicleServicesCfg {
  queues: {
    periodic-events: { path: data/periodic-events, sourceId: 100, name: periodic-
events },
    marketdata: { path: data/marketdata, sourceId: 1, name: marketdata },
    position: { path: data/position, sourceId: 2, name: position },
    daily-price: { path: data/daily-price, sourceId: 3, name: daily-price },
    web-page: { path: data/web-page, sourceId: 4, name: web-page },
  },
  services: {
    marketdata-service: {
      inputs: [ periodic-events ],
      output: marketdata,
      implClass: !type
software.chronicle.services.cookbook.example9b.service.impl.MarketDataServiceImpl,
      periodicUpdateMS: 1000,
    },
    position-service: {
      inputs: [ marketdata ],
      output: position,
      implClass: !type
software.chronicle.services.cookbook.example9b.service.impl.PositionServiceImpl,
    },
    daily-price-service: {
      inputs: [ marketdata ],
      output: daily-price,
      implClass: !type
software.chronicle.services.cookbook.example9b.service.impl.DailyPriceServiceImpl,
    },
    web-page-service: {
      inputs: [ position, daily-price ],
      output: web-page,
      implClass: !type
software.chronicle.services.cookbook.example9b.service.impl.WebPageServiceImpl,
    },
  }
}
Market-data-service acts as ingress to the application, simulating an adapter that reads from an external data
feed. It responds to PeriodicUpdate events by generating pseudo-randomly generated price updates for a small
group of ticker symbols.
These are posted to its output queue, marketdata, which is read by two separate services, positionservice
maintains position information and daily-price-service maintains price summary information.
Each of these two services posts to its own output queue, which are read by web-page-service, which presents
renders the data into HTML for publication to a browser.
In this example, we are not concerned with the actual rendering of the data into a browser.
If we run the application, then log messages will display the HTML at regular intervals.
Run this demo by clicking on the 'run' button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example9b && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
Listing 104. Log output excerpt
 _____ _                     _      _        _____                 _
/  __ \ |                   (_)    | |      /  ___|               (_)
| /  \/ |__  _ __ ___  _ __  _  ___| | ___  \ `--.  ___ _ ____   ___  ___ ___
___
| |   | '_ \| '__/ _ \| '_ \| |/ __| |/ _ \  `--. \/ _ \ '__\ \ / / |/ __/ _ \/
__|
| \__/\ | | | | | (_) | | | | | (__| |  __/ /\__/ /  __/ |   \ V /| | (_|  __/\__
\
 \____/_| |_|_|  \___/|_| |_|_|\___|_|\___| \____/ \___|_|    \_/
|_|\___\___||___/
:: Chronicle Services ::      (unknown version) Running under OpenJDK
Runtime Environment 1.8.0_345-b01 with 16 processors reported.
Process id:
69764 ...
[main/web-page-service] INFO Runner - Starting service web-page-service
[main/daily-price-service] INFO Runner - Starting service daily-price-service
[main/marketdata-service] INFO Runner - Starting service
marketdata-service [main/position-service] INFO Runner -
Starting service position-service... ...
[main/position-service] INFO Runner - runInitializationComplete
[main/position-service] INFO RunLoopControllerMain - running position-
service...
[main/daily-price-service] INFO Runner - runInitializationComplete
[main/daily-price-service] INFO RunLoopControllerMain - running daily-price-
service...
[main/marketdata-service] INFO PeriodicEventController - Writing periodic updates
to queue
target/data/periodic-events [main/marketdata-service] INFO Runner -
runInitializationComplete [main/marketdata-service] INFO
RunLoopControllerMain - running marketdata-service... ...
[main/web-page-service] INFO Runner - runInitializationComplete
[main/web-page-service] INFO RunLoopControllerMain - running web-
page-service... ...
WebPageService: <!DOCTYPE html><html><head><style>body {font-family: poppins,
Helvetica}table, td, th {border:2px solid}table {border-collapse: collapse}th,
td {font-size: 24px;  text-align:
center; width: 300px}th {color: #ffffff; background-color:
#181f43</style></head><body>
<h1>Best Bank</h1>
<h2>The Marketplace</h2>
<p><table>
<tr><th>Ticker</th><th>Open</th><th>Last</th><th>High</th><th>Low</th><th>Close</
th><tr><tr><td>T
SLA</td><td>0.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>129.27</td></tr>
</table></p>
<h2>My Portfolio</h2>
<p><table>
<tr><th>Ticker</th><th>#</th><th>Last</th><th>Value</th><tr></table></p>
</html></body>
 ...


Tracing an Event
 A separate application is used to display an event trace.
For demonstration purposes,
the application will read the latest event from the `web-
page` queue and display the trace of this event through the
application.
The details of the methods that perform the chaining of events through the application can be seen in the code <<
here >>.
After running the main application to populate the queues with data, we can run the tracer and the output will be:
Listing 105. Output from event tracing for the first event in the queue
... web-page-service:
web-page@0
  !software.chronicle.services.demo.example9b.dto.WebPage {
  eventId: periodicUpdate,
  eventTime: 2023-02-06T13:24:26.548515803,
  body: "<!DOCTYPE html><html><head><style>body {font-family: poppins,
Helvetica}table, td, th
{border:2px solid}table {border-collapse: collapse}th, td {font-size: 24px;
text-align: center; width: 300px}th {color: #ffffff; background-color:
#181f43</style></head><body>\n<h1>Best
Bank</h1>\n<h2>The
Marketplace</h2>\n<p><table>\n<tr><th>Ticker</th><th>Open</th><th>Last</th><th>Hi
gh</th><th>Low</
th><th>Close</th><tr><tr><td>TSLA</td><td>0.00</td><td>0.00</td><td>0.00</td><td>
0.00</td><td>120
.86</td></tr>\n</table></p>\n<h2>My
Portfolio</h2>\n<p><table>\n<tr><th>Ticker</th><th>#</th><th>Last</th><th>Value</
th><tr></table><
/p>\n</html></body>"
}
daily-price-service: daily-price@83296595738624
  !software.chronicle.services.demo.example9b.dto.EndOfDayPrice {
  eventId: periodicUpdate,
  eventTime: 2023-02-06T13:24:26.548515803,
  ticker: TSLA,
  opening: 0.0,
  last: 0.0,
  high: 0.0,
  low: 0.0,
  closing: 120.8559341430664
}
marketdata-service: marketdata@83296595738624
  !software.chronicle.services.demo.example9b.dto.MarketData {
  eventId: periodicUpdate,
  eventTime: 2023-02-06T13:24:26.548515803,
  ticker: TSLA,
  type: CLOSING,
  last: 120.8559341430664
}

The events are shown in a "trace-back" order, from the end of the service processing pipeline to the beginning. At each
stage, the name of the service that posted the message is shown, together with the queue name and index from
where the message was read. The payload of the message is also shown. Notice that the eventId and eventTime
properties passed with the message do not change, the event data is enriched at each stage from the original empty
payload of the PeriodicUpdate event through to the HTML that can be sent to the web page.
We can interpret the output against the service diagram shown above to illustrate the processing path.
9.3 Displaying Message Latencies in the Application
Problem
You want to examine the latencies introduced at each stage of an application.
Solution
Use the built-in ChronicleHistoryReader.
Discussion
Sometimes it is useful to know how long a message takes to pass through the various stages of a Chronicle Services
application. The MessageHistory posted to queues alongside messages carries timestamps that allow this to be
calculated, and the ChronicleHistoryReaderMain application, which is part of the Chronicle Queue library,
allows these to be processed into a histogram of latencies for each stage of the target application.
As an example, consider the simple Transaction service application used in Recipe 2.3 and others, with structure:

A histogram for a short run of this application can be generated using the following command:
Listing 106. Running Chronicle Queue History Reader
$ java -cp <classpath containing all dependencies> \
           software.chronicle.services.tools.ChronicleHistoryReaderMain \
           -d target/data/transactionOut -s services.yaml
We need to specify the path to the Chronicle Queue that contains the messages we want to check, and the service
configuration file.
When this is run, the output is as below.
This can also be run by clicking on the 'run' button:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example9c && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
Listing 107. Output from History Reader

121 of 134 | 9.3 Displaying Message Latencies in the Application


sourceId    transactionUpstream transactionUpstreamTotransactionSvc
transactionSvc     endToEnd count:                48
48                          48            48 50:               225280
966656                      466944       1474560
90:               417792                     1998848                      835584
2555904
99:              1277952                     5898240                     3604480
6422528 99.9:
99.99:
99.999:
99.9999: worst:           1277952                     5898240
3604480       6422528
The demo application is short, and the queue contains only very few messages, so the histogram here is not fully
populated, however the basics can be seen. The leftmost column represents percentiles of the messages, the other
columns contain the latencies at each of these percentiles for eash stage of the application:
transactionUpstream time for the message be generated and posted on the output of the upstream
service
transactionUpstreamTotransactionSvc time taken for the message to
reach the transaction service
transactionSvc time taken to handle the message in the transaction
service
endToEnd
total time in the application
Various command line arguments allow more flexibility over what information is displayed (for example displaying
timings on a per method basis rather than per service), and the units used (for example microseconds rather than the
default of nanoseconds).
The output shown here has been padded manually to make it slightly easier to read, owing to the long names in the
column headings. Output can also be generated in csv format, allowing the results to be imported into a spreadsheet
for further analysis.
122 of 134 | 9.3 Displaying Message Latencies in the Application
9.4 Simple Heartbeat Monitoring
Problem
You want to set up a simple heartbeat capability between two services.
Solution
Use HeartbeatSource and HeartbeatListener.
Discussion
Heartbeat is a useful feature of Chronicle services, which allows a service to verify that another service is available.
It is similar in concept to PeriodicUpdate, however its use cases are more focussed on discovering when there are
issues in communication between services.
This recipe demonstrates the simplest use of Heartbeat, simply operating between a pair of services. The example
used is, once more, the transaction service seen in earlier recipes. The structure of the application can be seen below:

and its configuration file is shown below:
Listing 108. Application Configuration
!ChronicleServicesCfg {
    queues: {
        transactionIn: { path: data/transactionIn, sourceId: 1 },
        transactionOut: { path: data/transactionOut, sourceId: 2 },
        upstreamIn: { path: data/upstreamIn, sourceId: 100 },
        downstreamOut: { path: data/downstreamOut, sourceId: 101 },
    },
    services: {
        transactionSvc: {
            inputs: [ transactionIn ],
            output: transactionOut,
            implClass: !type
software.chronicle.services.cookbook.example9c.services.Transact
ionSvcImpl,         },
        transactionUpstream: {
            inputs: [upstreamIn ],
            output: transactionIn,
            implClass: !type
software.chronicle.services.cookbook.example9c.services.TransactionSvcUpstream,
            periodicUpdateMS: 3000,
            periodicUpdateInitialMS: 500,
            heartbeatMS: 2000,
            heartbeatMSInitial: 1000,
        },
        transactionDownstream: {
            inputs: [ transactionOut ],
            output: downstreamOut,
            implClass: !type
software.chronicle.services.cookbook.example9c.services.TransactionSvcDownstream,
        }
    },
}
The main changes from previous examples of this application are in the configuration of the
transactionUpstream service.
1.	The input queue is required to supply the timer related events (periodicUpdate and heartbeat) to the service. Its
configuration is added to the queues section
2.	Timers for the periodicUpdate events: every 3 seconds after an intial delay of 0.5 seconds (to allow
configuration to complete)
3.	Timers for the heartbeat events: every 2 seconds after an initial delay of 1 second (to allow configuration to
complete)
The Upstream Service
The upstream service needs be defined to accept both periodicUpdate and heartbeat events, this is done by
implementing the necessary interfaces:
Listing 109. Upstream service class header
public class TransactionSvcUpstream     implements HeartbeatSource,
PeriodicUpdateSource, ServiceLifecycleListener {
The required methods must be defined in the class. In the case of HeartbeatSource there are two methods:
Listing 110. Methods for setting up Heartbeat


The first of these, heartbeatDefinitions(), is required by the interface, but in this example we do not use any
of the functionality it represents. The implementation is therefore empty apart from a diagnostic log message. We will
see a more realistic use case for this method in the following recipe.
The second of these, heartbeatTimer is the handler for the heartbeat events that are delivered to the service.
In this case, the handler will construct a heartbeat message containing the name of the sending service and the
current time. This is then posted to the output queue, from where it will be read by the downstream service
responsible for monitoring. In this example, this is the transactionSvc.
Also required is a handler for the periodicUpdate events:
Listing 111. Handler for Periodic Update events
  @Override
  public void periodicUpdate(long l) {
    LOG.info("Sending......");

out.transaction(transaction.accountNumber(34343434).entry(Entry.DEBIT).amount(100));

out.transaction(transaction.accountNumber(34343434).entry(Entry.DEBIT).amount(50));

out.transaction(transaction.accountNumber(45454545).entry(Entry.CREDIT).amount(10));
  }
This handler is used to post transactions to the main transaction service. It will be called (in this example) every 3
seconds. The same transactions are posted each time; for demo purposes this is adequate as the main aim is to show
the heartbeat behaviour, so this service remains active indefinitely.
The Main Service
The API for the transaction service must allow heartbeat events to be passed, so the input interface needs to reflect
that:
Listing 112. Input interface for main Transaction Service

The service implementation needs to provide the handler for theheartbeat events, in this case this it is simply a logging
method to show that the event has been received.
Listing 113. Handler for heartbeat events in Transaction Service


Running the Application
When the application is run, a number of log messages allow us to track its progress. We see the timer inputs (periodic
update and heartbeat) initialised.
Try running this example by clicking on the 'run' button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example9d && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
Listing 114. Output excerpt showing basic functionality
...
[main/transactionUpstream] INFO PeriodicEventController - Writing periodic
updates to queue
target/data/transactionDummyIn
[main/transactionUpstream] INFO HeartbeatController - Writing heartbeats to queue
target/data/transactionDumm
yIn ...
THe heartbeat functionality is shown through the following sequence, which occurs repeatedly:
Listing 115. Output excerpt showing heartbeat handling

In response to PeriodicEvents, the logs will show transactions being sent and processed: Listing 116.
Output excecrpt showing transaction processing in response to Periodic Events
...
[main/transactionUpstream] INFO TransactionSvcUpstream - Sending......
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Bad transaction: Account 34343434
has
insufficient funds for debit: 100.0 [0.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 50.0 to account
34343434
[main/transactionDownstream] INFO TransactionSvcDownstream - Account 34343434 has
balance 100.0
[main/transactionSvc] INFO TransactionSvcImpl - Bad transaction: Account 34343434
has
insufficient funds for debit: 50.0 [0.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545
[main/transactionDownstream] INFO TransactionSvcDownstream - Account 34343434 has
balance 50.0
[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
280.0


[main/transactionDownstream] INFO TransactionSvcDownstream - Account 45454545
has balance 10.0 ...
9.5 Using Heartbeats to Monitor Service Availability
Problem
You want to discover when a service, or one of its dependents, becomes unavailable/reavailable.
Solution
Set up hearbeat monitors with services and their dependencies and handle both Heartbeat and HearbeatError
events.
Discussion
Heartbeat events form part of a sophisticated capability provided by Chronicle Services to monitor service availability.
We can examine this by again looking at the Transaction Service that was described in recipe 9.4 and earlier:

In this simple example, the service transactionUpstream is a dependency of transactionSvc. The service
transactionDownstream will act as both a receiver of the transaction output messages, and heartbeat related
messages that indicate the status of transactionSvc.
Configuration for the application is shown here:
Listing 117. Application configuration
!ChronicleServicesCfg {
    queues: {
        transactionIn: { path: data/transactionIn, sourceId: 1 },
        transactionOut: { path: data/transactionOut, sourceId: 2 },
        upstreamIn: { path: data/upstreamIn, sourceId: 100 },
        downstreamOut: { path: data/downstreamOut, sourceId: 101 },
    },
    services: {
        transactionSvc: {
            inputs: [ transactionIn ],
            output: transactionOut,
            implClass: !type
software.chronicle.services.cookbook.example9e.services.TransactionSvcImpl,
            heartbeatMS: 2000,
            heartbeatMSInitial: 1500,
        },
        transactionUpstream: {
            inputs: [upstreamIn ],
            output: transactionIn,
            implClass: !type
software.chronicle.services.cookbook.example9e.services.TransactionSvcUpstream,
            periodicUpdateMS: 3000,
            periodicUpdateInitialMS: 500,
            heartbeatMS: 2000,
            heartbeatMSInitial: 1000,
        },
        transactionDownstream: {
            inputs: [ transactionOut ],
            output: downstreamOut,
            implClass: !type
software.chronicle.services.cookbook.example9e.services.TransactionSvcDownstream,
        }
    },
}
1.	The main service outputs heartbeats every 2 seconds, after an initial 1.5 second delay to allow initialisation to
complete.
2.	The upstream service outputs heartbeats every 2 seconds, after an initial 1 second delay.
3.	The upstream service also receives periodic update events, every 3 seconds after an initial 0.5 second delay. These
trigger the sending of transaction requests to the main service.
The HeartbeatService<O> Class
To enable checks on its dependencies and the signalling of any problems encountered, a service can make use of
functionality provided by Chronicle Services. This is encapsulated in the following class:
Listing 118. Heartbeat Service base class

The type parameter O represents the output API of the service, and is bounded to extend the
HeartbeatErrorListener class. This enables the posting of messages of type Heartbeat and
HeartbeatError.
So the service implementation class is defined as:
Listing 119. Transaction Service class header



    implements TransactionSvcIn, ServiceContextListener {
An additional step is required in the initialisation of the service, to identify and set up HeartbeatRecord objects
for the dependency monitoring provided by the HeartbeatService class. This can be done using the information
from the services.yaml file, using a utility method from Chronicle Services, in the serviceContext() method:
Listing 120. Configure heartbeat behaviour based on config file
  @Override
  public void serviceContext(ServiceContext context) {
    RunnerConfiguration runnerCfg = context.runnerCfg();
    HeartbeatDefinitions hbdefs = new HeartbeatDefnFromServices()
                                      .generate(4, runnerCfg);
    LOG.info(hbdefs.toString());
    heartbeatDefinitions(hbdefs);
   }
1.	Build a list of HeartbeatRecord objects, each containing a service with its dependencies (if any), and timeout
value specified here in seconds.
2.	Use the HeartbeatDefinitions list to initialise the service's heartbeat monitor.
The log message from this method displays the definitions that were discovered:
Listing 121. Log messages showing heartbeat configuration
[main/transactionSvc] INFO
software.chronicle.services.cookbook.example9d.services.TransactionSvcImpl -
!software.chronicle.services.api.dto.status.HeartbeatDefinitions {
  list: [
    { source: transactionSvc, timeoutInSecs: 4.0, dependsOn:
[ transactionUpstream ] },
    { source: transactionUpstream, timeoutInSecs: 4.0 }
  ]
}
The two services of interest are transactionSvc, which depends on transactionUpstream, the
transactionUpstream, which has no dependencies. For each of these, a timeout of 4 seconds is set, meaning
that if no heartbeat is received within 4 seconds then an error will be notified.
Processing Heartbeats
The HeartbeatService<o> class provides methods to process incoming Heartbeat messages from the
upstream service, and also to handle heartbeatTimer events for this service.
Each time a Heartbeat event is received from upstream, a timestamp in the HeartbeatRecord for that service is
updated. Each time the heartbeat timer fires in this service, a Heartbeat message is posted to the output, and the
list of dependencies is checked to see if any have not received a Heartbeat within the specified timeout period. If
any dependencies have timed out, a HeartbeatError message is constructed with the details and posted to the
output.
Running the Service
To illustrate this behaviour, we can alter slightly the way in which the transactionUpstream services sends
heartbeats and request messages to the transactionSvc service. Listing 122. Upstream service showing behaviour to
drive heartbeat behaviour


1.	Marks the service as a source of Heartbeat messages.
2.	Enables PeriodicEvent handling in the service.
3.	Allows access to service config to retrieve the service id.
4.	Allows state initialisation when service is started.
5.	Extract serviceId from configuration to use in Heartbeat messages.
6.	HeartbeatSource requires this method but here it is a no-op as this service has no dependencies.
7.	Don't send any messages downstream between the specified tick values.
8.	Called on periodicUpdate, update tick count and send transaction requests unless paused.
9.	Called on heartbeat timer. Send heartbeat message unless paused, which should trigger an error in monitoring
service.
10.	Initialisation of state once service is ready to run.
When the service is running, the log will show the "normal" sequence of events.
See this running by clicking on the 'run' button below:
<button onclick="run('cd SERVICES-COOKBOOK && cd Example9e && ./runDemo.sh')"
class="btn btn-primary btn-run">Run</button>
Listing 123. Log of normal application behaviour
[main/transactionUpstream] INFO TransactionSvcUpstream - ** Posting heartbeat
[main/transactionUpstream] INFO TransactionSvcUpstream - Sending transactions
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Bad transaction: Account 34343434
has
insufficient funds for debit: 100.0 [0.0]
[main/transactionDownstream] INFO TransactionSvcDownstream - Account 34343434 has
balance 100.0
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545 [main/transactionSvc] INFO TransactionSvcImpl - Succeeded:
Balance of account 45454545 is now
230.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Account 45454545 has
balance 10.0
[main/transactionDownstream] INFO TransactionSvcDownstream - ** Received
Heartbeat ** !Heartbeat
{
  source: transactionSvc,
  time: 2023-02-13T18:58:16.977087958
}
A Heartbeat is sent from the upstream service, the main service receives this and updates its monitor. The main
service sends a Heartbeat to the downstream service, indicating all is well. In the meantimer, transaction requests
are processed.
When the upstream service is paused, no messages (transactions or Heartbeat) are sent downstream The monitor
in the main service detects the timeout and sends an error downstream. Notice that it also sends a normal
Heartbeat as it is still running.
Listing 124. Log showing pausing of upstream service
[main/transactionUpstream] INFO TransactionSvcUpstream - ** Upstream heartbeat
paused ** [main/transactionUpstream] INFO TransactionSvcUpstream - Paused...
[main/transactionDownstream] INFO TransactionSvcDownstream - ** Received
Heartbeat ** !Heartbeat
{
  source: transactionSvc,
  time: 2023-02-13T18:58:26.980488133
}
[main/transactionDownstream] ERROR TransactionSvcDownstream - ** Received
Heartbeat error:**
!HeartbeatError {
  eventId: heartbeatTimer,
  eventTime: 2023-02-13T18:58:26.980488133,
  source: transactionSvc,
  upstreamSource: transactionUpstream,
  comments: "Missing heartbeat. Exceeded timeout 7.340122925 > 4.0 secs"
}
The messages from the upstream service confirm it is not sending anything. The HeartbeatError message
contains details of what has happened.
Once the "pause" time is over, the upstream service begins sending messages again, and the output pattern returns to
normal.
Listing 125. Log showing resumption of upstream service
[main/transactionUpstream] INFO TransactionSvcUpstream - ** Posting heartbeat
[main/transactionUpstream] INFO TransactionSvcUpstream - Sending transactions
[main/transactionSvc] INFO TransactionSvcImpl - Applying DEBIT of 100.0 to
account 34343434
[main/transactionSvc] INFO TransactionSvcImpl - Bad transaction: Account 34343434
has
insufficient funds for debit: 100.0 [0.0]
[main/transactionSvc] INFO TransactionSvcImpl - Applying CREDIT of 10.0 to
account 45454545
[main/transactionDownstream] INFO TransactionSvcDownstream - Account 34343434 has
balance 100.0


[main/transactionSvc] INFO TransactionSvcImpl - Succeeded: Balance of account
45454545 is now
250.0
[main/transactionDownstream] INFO TransactionSvcDownstream - Account 45454545
has balance 10.0
[main/transactionDownstream] INFO TransactionSvcDownstream - ** Received
Heartbeat ** !Heartbeat
{
  source: transactionSvc,
  time: 2023-02-13T18:58:32.981863303
}
 This example demonstrates the default handling of Heartbeat and HeartbeatError messages. It is
possible to override this behaviour for custom monitoring strategies.

